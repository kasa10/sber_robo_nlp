{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T21:01:47.375424Z",
     "end_time": "2024-04-04T21:01:47.394919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "file_path ='itmo_sber.csv'\n",
    "data = pd.read_csv('itmo_sber.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:10:02.803537Z",
     "end_time": "2024-04-04T20:10:02.993277Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                    0\n",
      "Задача                        0\n",
      "Обстановка                    0\n",
      "Оптимальный план              0\n",
      "Задача en                     0\n",
      "Обстановка en                 0\n",
      "Оптимальный план en           0\n",
      "Предсказанный план            0\n",
      "Успех предсказанного плана    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:10:04.948698Z",
     "end_time": "2024-04-04T20:10:04.982436Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                          Задача  \\\n",
      "0           0   Приготовить горячий шоколад.    \n",
      "1           1     Заказать доставку еды домой   \n",
      "2           2  Реставрация старого комода\\r\\n   \n",
      "3           3            Приготовить сырники.   \n",
      "4           4               Нарезать колбасу.   \n",
      "\n",
      "                                          Обстановка  \\\n",
      "0  кухня, молоко, какао, сахар, кастрюля, ложка, ...   \n",
      "1  мобильный телефон, ресторанное меню, интернет,...   \n",
      "2  Старый комод, повреждения, шпатель, шкурка, ма...   \n",
      "3  Кухня, столешница, творог, мука, яйцо, сахар, ...   \n",
      "4  Кухня, колбаса, нож, доска для резки, холодиль...   \n",
      "\n",
      "                                    Оптимальный план  \\\n",
      "0  Откройте дверь. Зайдите на кухню. Закрйоте две...   \n",
      "1  Найдите стол. Подойдите к столу. Найдите мобил...   \n",
      "2  Подойдите к комоду.Найдите шкурку.Возьмите шку...   \n",
      "3  Подойти к столешнице. Найти творог. Взять твор...   \n",
      "4  Подойти к холодильнику. Открыть холодильник. Н...   \n",
      "\n",
      "                                Задача en  \\\n",
      "0                  Prepare hot chocolate.   \n",
      "1        Order food delivery to your home   \n",
      "2  Restoration of an old chest of drawers   \n",
      "3                    Prepare cheesecakes.   \n",
      "4                        Cut the sausage.   \n",
      "\n",
      "                                       Обстановка en  \\\n",
      "0  kitchen, milk, cocoa, sugar, pan, spoon, cabin...   \n",
      "1  mobile phone, restaurant menu, internet, money...   \n",
      "2  Old chest of drawers, damage, spatula, sandpap...   \n",
      "3  Kitchen, countertop, cottage cheese, flour, eg...   \n",
      "4  Kitchen, sausage, knife, cutting board, refrig...   \n",
      "\n",
      "                                 Оптимальный план en  \\\n",
      "0  Open the door. Walk to the kitchen. Close the ...   \n",
      "1  Find a table. Come to the table. Find a mobile...   \n",
      "2  Walk to the chest of drawers. Find the sandpap...   \n",
      "3  Walk to the tabletop. Find cottage cheese. Gra...   \n",
      "4  Walk to the refrigerator. Open the refrigerato...   \n",
      "\n",
      "                                  Предсказанный план  \\\n",
      "0    Walk to the closet. Open the closet. Find a ...   \n",
      "1    Come to the table. Find your phone. Grab the...   \n",
      "2    Find the chest of drawers. Walk to the chest...   \n",
      "3    Walk to the tabletop. Find a bowl. Grab a bo...   \n",
      "4    Walk to the refrigerator. Open the refrigera...   \n",
      "\n",
      "   Успех предсказанного плана  \n",
      "0                           0  \n",
      "1                           1  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           1  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:10:05.236947Z",
     "end_time": "2024-04-04T20:10:05.278312Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успех предсказанного плана\n",
      "1    3234\n",
      "0    1600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Успех предсказанного плана'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:10:06.243784Z",
     "end_time": "2024-04-04T20:10:06.274075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  Успех предсказанного плана\n",
      "count  4834.000000                 4834.000000\n",
      "mean   2416.500000                    0.669011\n",
      "std    1395.599931                    0.470618\n",
      "min       0.000000                    0.000000\n",
      "25%    1208.250000                    0.000000\n",
      "50%    2416.500000                    1.000000\n",
      "75%    3624.750000                    1.000000\n",
      "max    4833.000000                    1.000000\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:10:06.645221Z",
     "end_time": "2024-04-04T20:10:06.790633Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:10:07.574776Z",
     "end_time": "2024-04-04T20:10:07.605774Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['Задача'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:10:08.293879Z",
     "end_time": "2024-04-04T20:10:08.360205Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4834, 5402)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:10:09.548094Z",
     "end_time": "2024-04-04T20:10:09.574002Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kiril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kiril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kiril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kiril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words and word.isalpha()]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['Задача'] = data['Задача'].apply(preprocess_text)\n",
    "data['Обстановка'] = data['Обстановка'].apply(preprocess_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T19:15:25.456770Z",
     "end_time": "2024-04-04T19:15:29.966752Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# # Инициализация векторизатора\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "#\n",
    "# # Объединяем текстовые данные для векторизации\n",
    "# combined_text = data['Задача'] + \" \" + data['Обстановка']\n",
    "# X = tfidf_vectorizer.fit_transform(combined_text)\n",
    "#\n",
    "# # Целевая переменная\n",
    "# y = data['Успех предсказанного плана']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T19:15:29.966752Z",
     "end_time": "2024-04-04T19:15:29.981186Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import re\n",
    "#\n",
    "# # Объединение текстовых полей\n",
    "# data['combined_text'] = data['Задача en'] + ' ' + data['Обстановка en'] + ' ' + data['Предсказанный план']\n",
    "#\n",
    "# # Функция для очистки и нормализации текста\n",
    "# def clean_text(text):\n",
    "#     text = text.lower()  # Приведение к нижнему регистру\n",
    "#     text = re.sub(r'\\s+', ' ', text)  # Удаление лишних пробелов\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)  # Удаление специальных символов\n",
    "#     return text\n",
    "#\n",
    "# # Применение функции очистки к каждой строке объединенного текстового поля\n",
    "# data['cleaned_text'] = data['combined_text'].apply(clean_text)\n",
    "#\n",
    "# # Подготовка данных и целевой переменной\n",
    "# X = data['cleaned_text']\n",
    "# y = data['Успех предсказанного плана']\n",
    "#\n",
    "# # Разделение данных на обучающую и тестовую выборки\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#\n",
    "# # Векторизация текста с использованием TF-IDF\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Ограничение на количество признаков для упрощения модели\n",
    "# X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "#\n",
    "# X_train_tfidf.shape, X_test_tfidf.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T19:15:29.981186Z",
     "end_time": "2024-04-04T19:15:30.014616Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAA\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка предобученной модели BERT и токенизатора\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "print('AAA')\n",
    "# Предварительная обработка текста\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "data['Предсказанный план'] = data['Предсказанный план'].apply(preprocess_text)\n",
    "data['Оптимальный план'] = data['Оптимальный план'].apply(preprocess_text)\n",
    "\n",
    "n=0\n",
    "# Функция для получения эмбеддингов текста с помощью BERT\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "    global n\n",
    "    n=n+1\n",
    "    if n%100==0:\n",
    "        print(n)\n",
    "    return embeddings\n",
    "\n",
    "# Получение эмбеддингов для \"Предсказанного плана\" и \"Оптимального плана\"\n",
    "predicted_plan_embeddings = np.array([get_bert_embeddings(text) for text in data['Предсказанный план']])\n",
    "optimal_plan_embeddings = np.array([get_bert_embeddings(text) for text in data['Оптимальный план']])\n",
    "\n",
    "# Вычисление сходства текстов с помощью косинусного сходства\n",
    "cosine_similarities = [np.dot(pred, opt.T) / (np.linalg.norm(pred) * np.linalg.norm(opt)) for pred, opt in zip(predicted_plan_embeddings, optimal_plan_embeddings)]\n",
    "\n",
    "# Подготовка данных и целевой переменной для классификации\n",
    "X = np.array(cosine_similarities).reshape(-1, 1)\n",
    "y = data['Успех предсказанного плана']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:10:14.073870Z",
     "end_time": "2024-04-04T20:48:15.342471Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Применение SMOTE для балансировки классов\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:51:27.755692Z",
     "end_time": "2024-04-04T20:51:28.079326Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5180, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_resampled.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:51:30.562605Z",
     "end_time": "2024-04-04T20:51:30.610130Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Баланс классов в X_train_resampled:\n",
      "{0: 2590, 1: 2590}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Посчитаем количество элементов каждого класса в y_train_resampled\n",
    "unique, counts = np.unique(y_train_resampled, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Баланс классов в X_train_resampled:\")\n",
    "print(class_counts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T21:01:53.232826Z",
     "end_time": "2024-04-04T21:01:53.249109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "X_train = X_train_resampled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T21:01:54.716992Z",
     "end_time": "2024-04-04T21:01:54.743868Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "y_train = y_train_resampled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T21:01:56.033532Z",
     "end_time": "2024-04-04T21:01:56.065416Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.5387797311271976\n",
      "F1 Score: 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Обучение классификатора\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовой выборке\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оценка точности модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of the model: {accuracy}')\n",
    "\n",
    "# Вычисление F1-меры\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T21:01:58.206089Z",
     "end_time": "2024-04-04T21:01:58.222772Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Баланс классов в X_train_resampled:\n",
      "{0: 433, 1: 534}\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем количество элементов каждого класса в y_train_resampled\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Баланс классов в X_train_resampled:\")\n",
    "print(class_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T21:02:03.446633Z",
     "end_time": "2024-04-04T21:02:03.477893Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OPTUNA log reg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-04 21:02:13,524] A new study created in memory with name: no-name-d2fe60d7-ad4f-448c-80db-ff1c9a45d6fb\n",
      "[I 2024-04-04 21:02:13,540] Trial 0 finished with value: 0.5387797311271976 and parameters: {'C': 228.767833837904, 'penalty': 'l2', 'max_iter': 463}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,555] Trial 1 finished with value: 0.5387797311271976 and parameters: {'C': 8435.539216557641, 'penalty': 'l2', 'max_iter': 394}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:13,573] Trial 2 finished with value: 0.5387797311271976 and parameters: {'C': 2063.236046016074, 'penalty': 'none', 'max_iter': 591}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,575] Trial 3 finished with value: 0.5387797311271976 and parameters: {'C': 4081.075895329201, 'penalty': 'l2', 'max_iter': 179}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,589] Trial 4 finished with value: 0.5387797311271976 and parameters: {'C': 9672.287418628288, 'penalty': 'l2', 'max_iter': 629}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:13,603] Trial 5 finished with value: 0.5387797311271976 and parameters: {'C': 5151.59121847598, 'penalty': 'none', 'max_iter': 327}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:13,619] Trial 6 finished with value: 0.5387797311271976 and parameters: {'C': 1103.4286923657903, 'penalty': 'none', 'max_iter': 106}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,629] Trial 7 finished with value: 0.5387797311271976 and parameters: {'C': 8049.675812673546, 'penalty': 'l2', 'max_iter': 458}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,650] Trial 8 finished with value: 0.5387797311271976 and parameters: {'C': 7252.9978473685, 'penalty': 'l2', 'max_iter': 738}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,660] Trial 9 finished with value: 0.5387797311271976 and parameters: {'C': 6166.051199674247, 'penalty': 'l2', 'max_iter': 924}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:13,677] Trial 10 finished with value: 0.5387797311271976 and parameters: {'C': 1001.9074650365296, 'penalty': 'none', 'max_iter': 844}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,708] Trial 11 finished with value: 0.5387797311271976 and parameters: {'C': 3026.2395542013037, 'penalty': 'l2', 'max_iter': 402}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,739] Trial 12 finished with value: 0.5387797311271976 and parameters: {'C': 174.70774918725138, 'penalty': 'l2', 'max_iter': 308}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,771] Trial 13 finished with value: 0.5387797311271976 and parameters: {'C': 3571.9168022898975, 'penalty': 'l2', 'max_iter': 499}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,787] Trial 14 finished with value: 0.5387797311271976 and parameters: {'C': 5538.770680385696, 'penalty': 'l2', 'max_iter': 264}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,818] Trial 15 finished with value: 0.5387797311271976 and parameters: {'C': 2711.5727738962305, 'penalty': 'l2', 'max_iter': 690}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,850] Trial 16 finished with value: 0.5387797311271976 and parameters: {'C': 4184.343548394667, 'penalty': 'l2', 'max_iter': 401}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,882] Trial 17 finished with value: 0.5387797311271976 and parameters: {'C': 9922.154872848543, 'penalty': 'l2', 'max_iter': 526}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:13,905] Trial 18 finished with value: 0.5387797311271976 and parameters: {'C': 6466.095629804277, 'penalty': 'none', 'max_iter': 210}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,930] Trial 19 finished with value: 0.5387797311271976 and parameters: {'C': 4535.9671620154095, 'penalty': 'l2', 'max_iter': 378}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:13,974] Trial 20 finished with value: 0.5387797311271976 and parameters: {'C': 8727.022534910891, 'penalty': 'l2', 'max_iter': 752}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:13,994] Trial 21 finished with value: 0.5387797311271976 and parameters: {'C': 71.184579447862, 'penalty': 'none', 'max_iter': 578}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,024] Trial 22 finished with value: 0.5387797311271976 and parameters: {'C': 1977.5573212425722, 'penalty': 'none', 'max_iter': 602}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,055] Trial 23 finished with value: 0.5387797311271976 and parameters: {'C': 2221.5047828827855, 'penalty': 'none', 'max_iter': 465}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,071] Trial 24 finished with value: 0.5387797311271976 and parameters: {'C': 1649.9082654643476, 'penalty': 'none', 'max_iter': 682}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,087] Trial 25 finished with value: 0.5387797311271976 and parameters: {'C': 968.1575604538889, 'penalty': 'none', 'max_iter': 532}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,118] Trial 26 finished with value: 0.5387797311271976 and parameters: {'C': 3154.137535964498, 'penalty': 'none', 'max_iter': 992}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,150] Trial 27 finished with value: 0.5387797311271976 and parameters: {'C': 2547.001640878693, 'penalty': 'l2', 'max_iter': 446}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,167] Trial 28 finished with value: 0.5387797311271976 and parameters: {'C': 1688.068643607308, 'penalty': 'none', 'max_iter': 346}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,198] Trial 29 finished with value: 0.5387797311271976 and parameters: {'C': 3840.136071563239, 'penalty': 'l2', 'max_iter': 272}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,213] Trial 30 finished with value: 0.5387797311271976 and parameters: {'C': 4853.395364539411, 'penalty': 'l2', 'max_iter': 631}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,245] Trial 31 finished with value: 0.5387797311271976 and parameters: {'C': 3943.7601693546385, 'penalty': 'l2', 'max_iter': 117}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,261] Trial 32 finished with value: 0.5387797311271976 and parameters: {'C': 9372.194389632223, 'penalty': 'l2', 'max_iter': 219}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,277] Trial 33 finished with value: 0.5387797311271976 and parameters: {'C': 4595.0241829558545, 'penalty': 'l2', 'max_iter': 183}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,308] Trial 34 finished with value: 0.5387797311271976 and parameters: {'C': 3422.4454258523956, 'penalty': 'l2', 'max_iter': 632}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,324] Trial 35 finished with value: 0.5387797311271976 and parameters: {'C': 5496.030727925134, 'penalty': 'l2', 'max_iter': 169}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,355] Trial 36 finished with value: 0.5387797311271976 and parameters: {'C': 7281.263400819753, 'penalty': 'none', 'max_iter': 446}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,387] Trial 37 finished with value: 0.5387797311271976 and parameters: {'C': 2599.8219474294897, 'penalty': 'l2', 'max_iter': 563}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,402] Trial 38 finished with value: 0.5387797311271976 and parameters: {'C': 1225.1240075280252, 'penalty': 'none', 'max_iter': 771}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,419] Trial 39 finished with value: 0.5387797311271976 and parameters: {'C': 745.8110630841013, 'penalty': 'l2', 'max_iter': 322}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,450] Trial 40 finished with value: 0.5387797311271976 and parameters: {'C': 629.3702793708511, 'penalty': 'l2', 'max_iter': 478}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,472] Trial 41 finished with value: 0.5387797311271976 and parameters: {'C': 8358.511073945007, 'penalty': 'l2', 'max_iter': 693}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,483] Trial 42 finished with value: 0.5387797311271976 and parameters: {'C': 7782.3878144760165, 'penalty': 'l2', 'max_iter': 816}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,514] Trial 43 finished with value: 0.5387797311271976 and parameters: {'C': 8929.521596893106, 'penalty': 'l2', 'max_iter': 632}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,529] Trial 44 finished with value: 0.5387797311271976 and parameters: {'C': 9762.947761597488, 'penalty': 'l2', 'max_iter': 504}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,561] Trial 45 finished with value: 0.5387797311271976 and parameters: {'C': 9388.082440268967, 'penalty': 'l2', 'max_iter': 372}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,614] Trial 46 finished with value: 0.5387797311271976 and parameters: {'C': 6303.329071138498, 'penalty': 'l2', 'max_iter': 424}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,640] Trial 47 finished with value: 0.5387797311271976 and parameters: {'C': 2990.9565627914762, 'penalty': 'l2', 'max_iter': 551}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,656] Trial 48 finished with value: 0.5387797311271976 and parameters: {'C': 459.0099623015534, 'penalty': 'none', 'max_iter': 100}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,672] Trial 49 finished with value: 0.5387797311271976 and parameters: {'C': 112.94859069530776, 'penalty': 'l2', 'max_iter': 283}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,688] Trial 50 finished with value: 0.5387797311271976 and parameters: {'C': 1233.8819896164546, 'penalty': 'l2', 'max_iter': 668}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,703] Trial 51 finished with value: 0.5387797311271976 and parameters: {'C': 5580.784026285146, 'penalty': 'none', 'max_iter': 237}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,720] Trial 52 finished with value: 0.5387797311271976 and parameters: {'C': 6826.754913055607, 'penalty': 'none', 'max_iter': 397}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,735] Trial 53 finished with value: 0.5387797311271976 and parameters: {'C': 3447.5247791307115, 'penalty': 'none', 'max_iter': 341}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,754] Trial 54 finished with value: 0.5387797311271976 and parameters: {'C': 4262.498394489535, 'penalty': 'none', 'max_iter': 504}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,766] Trial 55 finished with value: 0.5387797311271976 and parameters: {'C': 2210.367793948337, 'penalty': 'none', 'max_iter': 596}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,798] Trial 56 finished with value: 0.5387797311271976 and parameters: {'C': 5187.107446974256, 'penalty': 'none', 'max_iter': 147}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,813] Trial 57 finished with value: 0.5387797311271976 and parameters: {'C': 1619.5866991299874, 'penalty': 'l2', 'max_iter': 298}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,829] Trial 58 finished with value: 0.5387797311271976 and parameters: {'C': 8149.825154186473, 'penalty': 'none', 'max_iter': 365}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,854] Trial 59 finished with value: 0.5387797311271976 and parameters: {'C': 2927.4229700993546, 'penalty': 'l2', 'max_iter': 433}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,876] Trial 60 finished with value: 0.5387797311271976 and parameters: {'C': 3727.1569619247434, 'penalty': 'l2', 'max_iter': 485}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,896] Trial 61 finished with value: 0.5387797311271976 and parameters: {'C': 6020.936844320767, 'penalty': 'none', 'max_iter': 133}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,924] Trial 62 finished with value: 0.5387797311271976 and parameters: {'C': 262.1266276459367, 'penalty': 'none', 'max_iter': 171}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,940] Trial 63 finished with value: 0.5387797311271976 and parameters: {'C': 909.3231009089919, 'penalty': 'none', 'max_iter': 223}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,956] Trial 64 finished with value: 0.5387797311271976 and parameters: {'C': 4105.566375139142, 'penalty': 'none', 'max_iter': 527}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:14,972] Trial 65 finished with value: 0.5387797311271976 and parameters: {'C': 390.28374883725076, 'penalty': 'none', 'max_iter': 721}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:14,987] Trial 66 finished with value: 0.5387797311271976 and parameters: {'C': 2010.9236723998742, 'penalty': 'l2', 'max_iter': 244}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,004] Trial 67 finished with value: 0.5387797311271976 and parameters: {'C': 1341.6645147990857, 'penalty': 'none', 'max_iter': 589}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,034] Trial 68 finished with value: 0.5387797311271976 and parameters: {'C': 31.034525069069787, 'penalty': 'l2', 'max_iter': 190}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,034] Trial 69 finished with value: 0.5387797311271976 and parameters: {'C': 766.7591081332307, 'penalty': 'none', 'max_iter': 407}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,055] Trial 70 finished with value: 0.5387797311271976 and parameters: {'C': 2535.0964545663173, 'penalty': 'l2', 'max_iter': 342}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,082] Trial 71 finished with value: 0.5387797311271976 and parameters: {'C': 7566.846234805361, 'penalty': 'l2', 'max_iter': 465}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,098] Trial 72 finished with value: 0.5387797311271976 and parameters: {'C': 6972.08132747015, 'penalty': 'l2', 'max_iter': 530}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,113] Trial 73 finished with value: 0.5387797311271976 and parameters: {'C': 8600.678302383445, 'penalty': 'l2', 'max_iter': 617}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,129] Trial 74 finished with value: 0.5387797311271976 and parameters: {'C': 7934.646525311289, 'penalty': 'l2', 'max_iter': 569}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,162] Trial 75 finished with value: 0.5387797311271976 and parameters: {'C': 9097.978417760833, 'penalty': 'l2', 'max_iter': 658}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,177] Trial 76 finished with value: 0.5387797311271976 and parameters: {'C': 9872.48521003014, 'penalty': 'l2', 'max_iter': 141}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,193] Trial 77 finished with value: 0.5387797311271976 and parameters: {'C': 8370.876863890226, 'penalty': 'l2', 'max_iter': 402}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,225] Trial 78 finished with value: 0.5387797311271976 and parameters: {'C': 4663.3598311315045, 'penalty': 'none', 'max_iter': 459}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,242] Trial 79 finished with value: 0.5387797311271976 and parameters: {'C': 9448.210725971174, 'penalty': 'l2', 'max_iter': 311}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,272] Trial 80 finished with value: 0.5387797311271976 and parameters: {'C': 574.6863343301416, 'penalty': 'l2', 'max_iter': 262}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,299] Trial 81 finished with value: 0.5387797311271976 and parameters: {'C': 7398.755612607753, 'penalty': 'l2', 'max_iter': 830}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,383] Trial 82 finished with value: 0.5387797311271976 and parameters: {'C': 8914.783094097336, 'penalty': 'l2', 'max_iter': 864}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,414] Trial 83 finished with value: 0.5387797311271976 and parameters: {'C': 8014.897629018979, 'penalty': 'l2', 'max_iter': 785}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,434] Trial 84 finished with value: 0.5387797311271976 and parameters: {'C': 7665.697904519677, 'penalty': 'l2', 'max_iter': 739}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,467] Trial 85 finished with value: 0.5387797311271976 and parameters: {'C': 8582.483360535112, 'penalty': 'none', 'max_iter': 109}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,486] Trial 86 finished with value: 0.5387797311271976 and parameters: {'C': 7185.795767339472, 'penalty': 'l2', 'max_iter': 706}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,517] Trial 87 finished with value: 0.5387797311271976 and parameters: {'C': 6498.711843071273, 'penalty': 'l2', 'max_iter': 886}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,556] Trial 88 finished with value: 0.5387797311271976 and parameters: {'C': 4363.379881649468, 'penalty': 'none', 'max_iter': 493}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,565] Trial 89 finished with value: 0.5387797311271976 and parameters: {'C': 8229.777973722114, 'penalty': 'l2', 'max_iter': 551}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,620] Trial 90 finished with value: 0.5387797311271976 and parameters: {'C': 3322.308171922902, 'penalty': 'none', 'max_iter': 1000}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,656] Trial 91 finished with value: 0.5387797311271976 and parameters: {'C': 5851.9049564460065, 'penalty': 'l2', 'max_iter': 650}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,668] Trial 92 finished with value: 0.5387797311271976 and parameters: {'C': 5184.786399857971, 'penalty': 'l2', 'max_iter': 917}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,683] Trial 93 finished with value: 0.5387797311271976 and parameters: {'C': 1026.9270753198496, 'penalty': 'l2', 'max_iter': 972}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,699] Trial 94 finished with value: 0.5387797311271976 and parameters: {'C': 7837.437566288138, 'penalty': 'l2', 'max_iter': 428}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,731] Trial 95 finished with value: 0.5387797311271976 and parameters: {'C': 4876.8106976919535, 'penalty': 'l2', 'max_iter': 385}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,746] Trial 96 finished with value: 0.5387797311271976 and parameters: {'C': 3942.9798822785715, 'penalty': 'none', 'max_iter': 926}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,762] Trial 97 finished with value: 0.5387797311271976 and parameters: {'C': 3686.2448024921086, 'penalty': 'l2', 'max_iter': 512}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,794] Trial 98 finished with value: 0.5387797311271976 and parameters: {'C': 7542.449539277216, 'penalty': 'l2', 'max_iter': 801}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,809] Trial 99 finished with value: 0.5387797311271976 and parameters: {'C': 375.3867569926226, 'penalty': 'none', 'max_iter': 360}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,841] Trial 100 finished with value: 0.5387797311271976 and parameters: {'C': 6725.058605120636, 'penalty': 'l2', 'max_iter': 452}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,857] Trial 101 finished with value: 0.5387797311271976 and parameters: {'C': 1622.7113921004973, 'penalty': 'none', 'max_iter': 947}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,889] Trial 102 finished with value: 0.5387797311271976 and parameters: {'C': 1429.2995690362516, 'penalty': 'none', 'max_iter': 835}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,904] Trial 103 finished with value: 0.5387797311271976 and parameters: {'C': 1030.4829113167, 'penalty': 'none', 'max_iter': 882}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,942] Trial 104 finished with value: 0.5387797311271976 and parameters: {'C': 814.2623090515004, 'penalty': 'none', 'max_iter': 192}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,956] Trial 105 finished with value: 0.5387797311271976 and parameters: {'C': 578.1186730037556, 'penalty': 'none', 'max_iter': 746}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:15,983] Trial 106 finished with value: 0.5387797311271976 and parameters: {'C': 1924.3983340202035, 'penalty': 'l2', 'max_iter': 605}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:15,998] Trial 107 finished with value: 0.5387797311271976 and parameters: {'C': 291.1335581457679, 'penalty': 'none', 'max_iter': 158}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,030] Trial 108 finished with value: 0.5387797311271976 and parameters: {'C': 177.20037934959237, 'penalty': 'l2', 'max_iter': 766}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,056] Trial 109 finished with value: 0.5387797311271976 and parameters: {'C': 7137.471448501961, 'penalty': 'l2', 'max_iter': 121}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:16,078] Trial 110 finished with value: 0.5387797311271976 and parameters: {'C': 690.7851898806957, 'penalty': 'none', 'max_iter': 473}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,094] Trial 111 finished with value: 0.5387797311271976 and parameters: {'C': 2526.3273738662733, 'penalty': 'l2', 'max_iter': 418}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,110] Trial 112 finished with value: 0.5387797311271976 and parameters: {'C': 2763.514597388643, 'penalty': 'l2', 'max_iter': 379}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,141] Trial 113 finished with value: 0.5387797311271976 and parameters: {'C': 1067.8807534044072, 'penalty': 'l2', 'max_iter': 443}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,157] Trial 114 finished with value: 0.5387797311271976 and parameters: {'C': 3158.1989368172303, 'penalty': 'l2', 'max_iter': 679}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,173] Trial 115 finished with value: 0.5387797311271976 and parameters: {'C': 1460.27757518572, 'penalty': 'l2', 'max_iter': 326}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,204] Trial 116 finished with value: 0.5387797311271976 and parameters: {'C': 8023.497335926035, 'penalty': 'l2', 'max_iter': 582}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:16,220] Trial 117 finished with value: 0.5387797311271976 and parameters: {'C': 1180.0590416617827, 'penalty': 'none', 'max_iter': 545}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,236] Trial 118 finished with value: 0.5387797311271976 and parameters: {'C': 8369.00470231142, 'penalty': 'l2', 'max_iter': 299}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,268] Trial 119 finished with value: 0.5387797311271976 and parameters: {'C': 7785.857160216039, 'penalty': 'l2', 'max_iter': 397}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:16,283] Trial 120 finished with value: 0.5387797311271976 and parameters: {'C': 9720.601457981948, 'penalty': 'none', 'max_iter': 724}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,315] Trial 121 finished with value: 0.5387797311271976 and parameters: {'C': 6.212646359754814, 'penalty': 'l2', 'max_iter': 356}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,331] Trial 122 finished with value: 0.5387797311271976 and parameters: {'C': 484.1113632163515, 'penalty': 'l2', 'max_iter': 336}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,362] Trial 123 finished with value: 0.5387797311271976 and parameters: {'C': 767.0945620706495, 'penalty': 'l2', 'max_iter': 263}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,379] Trial 124 finished with value: 0.5387797311271976 and parameters: {'C': 8787.929458295386, 'penalty': 'l2', 'max_iter': 215}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,394] Trial 125 finished with value: 0.5387797311271976 and parameters: {'C': 4410.939366031229, 'penalty': 'l2', 'max_iter': 280}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,426] Trial 126 finished with value: 0.5387797311271976 and parameters: {'C': 9190.839789820035, 'penalty': 'l2', 'max_iter': 853}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:16,458] Trial 127 finished with value: 0.5387797311271976 and parameters: {'C': 8566.395120595556, 'penalty': 'none', 'max_iter': 625}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,473] Trial 128 finished with value: 0.5387797311271976 and parameters: {'C': 1822.4710673834645, 'penalty': 'l2', 'max_iter': 416}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,505] Trial 129 finished with value: 0.5387797311271976 and parameters: {'C': 888.4806509974103, 'penalty': 'l2', 'max_iter': 516}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:16,522] Trial 130 finished with value: 0.5387797311271976 and parameters: {'C': 2228.996281787439, 'penalty': 'none', 'max_iter': 902}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,556] Trial 131 finished with value: 0.5387797311271976 and parameters: {'C': 3662.96342971728, 'penalty': 'l2', 'max_iter': 488}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,584] Trial 132 finished with value: 0.5387797311271976 and parameters: {'C': 4025.017896043856, 'penalty': 'l2', 'max_iter': 435}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,616] Trial 133 finished with value: 0.5387797311271976 and parameters: {'C': 502.442334002829, 'penalty': 'l2', 'max_iter': 450}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,632] Trial 134 finished with value: 0.5387797311271976 and parameters: {'C': 7389.514500266493, 'penalty': 'l2', 'max_iter': 497}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,664] Trial 135 finished with value: 0.5387797311271976 and parameters: {'C': 3481.0892311977514, 'penalty': 'l2', 'max_iter': 962}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,692] Trial 136 finished with value: 0.5387797311271976 and parameters: {'C': 152.95041334892778, 'penalty': 'l2', 'max_iter': 478}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:16,724] Trial 137 finished with value: 0.5387797311271976 and parameters: {'C': 4232.236065589691, 'penalty': 'none', 'max_iter': 565}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,756] Trial 138 finished with value: 0.5387797311271976 and parameters: {'C': 6294.752756370736, 'penalty': 'l2', 'max_iter': 239}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,788] Trial 139 finished with value: 0.5387797311271976 and parameters: {'C': 5609.934846650789, 'penalty': 'l2', 'max_iter': 388}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:16,830] Trial 140 finished with value: 0.5387797311271976 and parameters: {'C': 3865.0754301402167, 'penalty': 'none', 'max_iter': 644}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,856] Trial 141 finished with value: 0.5387797311271976 and parameters: {'C': 4925.1038230321265, 'penalty': 'l2', 'max_iter': 308}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,878] Trial 142 finished with value: 0.5387797311271976 and parameters: {'C': 4705.965908298888, 'penalty': 'l2', 'max_iter': 206}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,909] Trial 143 finished with value: 0.5387797311271976 and parameters: {'C': 5093.789826599739, 'penalty': 'l2', 'max_iter': 291}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,925] Trial 144 finished with value: 0.5387797311271976 and parameters: {'C': 5262.158848327547, 'penalty': 'l2', 'max_iter': 161}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,957] Trial 145 finished with value: 0.5387797311271976 and parameters: {'C': 5378.703647070849, 'penalty': 'l2', 'max_iter': 126}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:16,988] Trial 146 finished with value: 0.5387797311271976 and parameters: {'C': 1215.5186041554875, 'penalty': 'l2', 'max_iter': 542}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:17,020] Trial 147 finished with value: 0.5387797311271976 and parameters: {'C': 309.39708749743124, 'penalty': 'none', 'max_iter': 323}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,035] Trial 148 finished with value: 0.5387797311271976 and parameters: {'C': 8176.2851787363525, 'penalty': 'l2', 'max_iter': 361}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,067] Trial 149 finished with value: 0.5387797311271976 and parameters: {'C': 5537.3535710272845, 'penalty': 'l2', 'max_iter': 260}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:17,098] Trial 150 finished with value: 0.5387797311271976 and parameters: {'C': 5941.608090556736, 'penalty': 'none', 'max_iter': 462}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,138] Trial 151 finished with value: 0.5387797311271976 and parameters: {'C': 3130.278312208583, 'penalty': 'l2', 'max_iter': 611}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,156] Trial 152 finished with value: 0.5387797311271976 and parameters: {'C': 2358.0846270688494, 'penalty': 'l2', 'max_iter': 673}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,191] Trial 153 finished with value: 0.5387797311271976 and parameters: {'C': 2822.5255633714874, 'penalty': 'l2', 'max_iter': 696}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,223] Trial 154 finished with value: 0.5387797311271976 and parameters: {'C': 8996.72589970942, 'penalty': 'l2', 'max_iter': 186}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,257] Trial 155 finished with value: 0.5387797311271976 and parameters: {'C': 2695.745495741614, 'penalty': 'l2', 'max_iter': 589}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,293] Trial 156 finished with value: 0.5387797311271976 and parameters: {'C': 3079.2641614464987, 'penalty': 'l2', 'max_iter': 726}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:17,317] Trial 157 finished with value: 0.5387797311271976 and parameters: {'C': 6890.504796472643, 'penalty': 'none', 'max_iter': 790}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,333] Trial 158 finished with value: 0.5387797311271976 and parameters: {'C': 2906.1950202056605, 'penalty': 'l2', 'max_iter': 647}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,365] Trial 159 finished with value: 0.5387797311271976 and parameters: {'C': 1484.0626485209898, 'penalty': 'l2', 'max_iter': 405}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:17,396] Trial 160 finished with value: 0.5387797311271976 and parameters: {'C': 1717.4878771975184, 'penalty': 'none', 'max_iter': 512}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,428] Trial 161 finished with value: 0.5387797311271976 and parameters: {'C': 3358.368677337706, 'penalty': 'l2', 'max_iter': 375}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,465] Trial 162 finished with value: 0.5387797311271976 and parameters: {'C': 4547.120684820445, 'penalty': 'l2', 'max_iter': 434}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,491] Trial 163 finished with value: 0.5387797311271976 and parameters: {'C': 2011.3387684452218, 'penalty': 'l2', 'max_iter': 823}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,522] Trial 164 finished with value: 0.5387797311271976 and parameters: {'C': 4131.049135996764, 'penalty': 'l2', 'max_iter': 345}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,557] Trial 165 finished with value: 0.5387797311271976 and parameters: {'C': 7677.824153930638, 'penalty': 'l2', 'max_iter': 763}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,570] Trial 166 finished with value: 0.5387797311271976 and parameters: {'C': 9241.886100851658, 'penalty': 'l2', 'max_iter': 416}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,636] Trial 167 finished with value: 0.5387797311271976 and parameters: {'C': 8717.698581174796, 'penalty': 'l2', 'max_iter': 106}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:17,671] Trial 168 finished with value: 0.5387797311271976 and parameters: {'C': 9655.223281590499, 'penalty': 'none', 'max_iter': 468}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,695] Trial 169 finished with value: 0.5387797311271976 and parameters: {'C': 679.2224489281289, 'penalty': 'l2', 'max_iter': 932}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,726] Trial 170 finished with value: 0.5387797311271976 and parameters: {'C': 9496.927063684088, 'penalty': 'l2', 'max_iter': 859}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,757] Trial 171 finished with value: 0.5387797311271976 and parameters: {'C': 7149.364730753941, 'penalty': 'l2', 'max_iter': 542}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,789] Trial 172 finished with value: 0.5387797311271976 and parameters: {'C': 9886.76042796345, 'penalty': 'l2', 'max_iter': 140}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,821] Trial 173 finished with value: 0.5387797311271976 and parameters: {'C': 9711.023265332618, 'penalty': 'l2', 'max_iter': 485}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,852] Trial 174 finished with value: 0.5387797311271976 and parameters: {'C': 9268.447499493299, 'penalty': 'l2', 'max_iter': 564}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:17,868] Trial 175 finished with value: 0.5387797311271976 and parameters: {'C': 9901.56781365984, 'penalty': 'none', 'max_iter': 532}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,900] Trial 176 finished with value: 0.5387797311271976 and parameters: {'C': 3631.5191007365725, 'penalty': 'l2', 'max_iter': 314}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,931] Trial 177 finished with value: 0.5387797311271976 and parameters: {'C': 4796.136413543474, 'penalty': 'l2', 'max_iter': 449}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:17,963] Trial 178 finished with value: 0.5387797311271976 and parameters: {'C': 9996.606807515742, 'penalty': 'l2', 'max_iter': 248}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:17,995] Trial 179 finished with value: 0.5387797311271976 and parameters: {'C': 9482.808661282612, 'penalty': 'none', 'max_iter': 707}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,026] Trial 180 finished with value: 0.5387797311271976 and parameters: {'C': 7925.34055107685, 'penalty': 'l2', 'max_iter': 499}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:18,042] Trial 181 finished with value: 0.5387797311271976 and parameters: {'C': 5792.6589223935825, 'penalty': 'none', 'max_iter': 219}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:18,073] Trial 182 finished with value: 0.5387797311271976 and parameters: {'C': 6303.61833908416, 'penalty': 'none', 'max_iter': 981}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:18,105] Trial 183 finished with value: 0.5387797311271976 and parameters: {'C': 10.818320159775908, 'penalty': 'none', 'max_iter': 522}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:18,136] Trial 184 finished with value: 0.5387797311271976 and parameters: {'C': 7350.3405006192, 'penalty': 'none', 'max_iter': 198}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:18,167] Trial 185 finished with value: 0.5387797311271976 and parameters: {'C': 6742.280723868261, 'penalty': 'none', 'max_iter': 287}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,199] Trial 186 finished with value: 0.5387797311271976 and parameters: {'C': 2556.316520051997, 'penalty': 'l2', 'max_iter': 275}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,216] Trial 187 finished with value: 0.5387797311271976 and parameters: {'C': 902.957959017959, 'penalty': 'l2', 'max_iter': 175}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:18,246] Trial 188 finished with value: 0.5387797311271976 and parameters: {'C': 379.37947362962075, 'penalty': 'none', 'max_iter': 632}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,279] Trial 189 finished with value: 0.5387797311271976 and parameters: {'C': 6591.285527167736, 'penalty': 'l2', 'max_iter': 228}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,309] Trial 190 finished with value: 0.5387797311271976 and parameters: {'C': 3266.6617859293597, 'penalty': 'l2', 'max_iter': 603}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,325] Trial 191 finished with value: 0.5387797311271976 and parameters: {'C': 4426.758268588713, 'penalty': 'l2', 'max_iter': 391}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,358] Trial 192 finished with value: 0.5387797311271976 and parameters: {'C': 4210.089750546082, 'penalty': 'l2', 'max_iter': 365}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,389] Trial 193 finished with value: 0.5387797311271976 and parameters: {'C': 1304.1817725898618, 'penalty': 'l2', 'max_iter': 348}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,420] Trial 194 finished with value: 0.5387797311271976 and parameters: {'C': 8405.832105892368, 'penalty': 'l2', 'max_iter': 424}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,451] Trial 195 finished with value: 0.5387797311271976 and parameters: {'C': 7538.184007361452, 'penalty': 'l2', 'max_iter': 398}. Best is trial 0 with value: 0.5387797311271976.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2024-04-04 21:02:18,485] Trial 196 finished with value: 0.5387797311271976 and parameters: {'C': 3837.7210080763007, 'penalty': 'none', 'max_iter': 377}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,499] Trial 197 finished with value: 0.5387797311271976 and parameters: {'C': 1067.1898296873023, 'penalty': 'l2', 'max_iter': 578}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,547] Trial 198 finished with value: 0.5387797311271976 and parameters: {'C': 6967.334171589795, 'penalty': 'l2', 'max_iter': 324}. Best is trial 0 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:02:18,564] Trial 199 finished with value: 0.5387797311271976 and parameters: {'C': 6079.4465559626615, 'penalty': 'l2', 'max_iter': 339}. Best is trial 0 with value: 0.5387797311271976.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Определите пространство поиска гиперпараметров\n",
    "    C = trial.suggest_float(\"C\", 0.0001, 10000)\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l2\", \"none\"])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100, 1000)\n",
    "\n",
    "    # Модель логистической регрессии\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        max_iter=max_iter\n",
    "    )\n",
    "\n",
    "    # Обучение\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Предсказание\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "#лучшие гиперпараметры\n",
    "best_params = study.best_params\n",
    "best_C = best_params[\"C\"]\n",
    "best_penalty = best_params[\"penalty\"]\n",
    "best_max_iter = best_params[\"max_iter\"]\n",
    "\n",
    "#модель с лучшими гиперпараметрами\n",
    "best_model = LogisticRegression(\n",
    "    C=best_C,\n",
    "    penalty=best_penalty,\n",
    "    max_iter=best_max_iter\n",
    ")\n",
    "\n",
    "\n",
    "best_model.fit(X, y)\n",
    "\n",
    "y_pred=best_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T21:02:13.550404Z",
     "end_time": "2024-04-04T21:02:18.596240Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 228.767833837904, 'penalty': 'l2', 'max_iter': 463}\n",
      "Accuracy: 0.67\n",
      "F1 Score: 0.80\n",
      "ROC-AUC Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "#Лучшие гиперпараметры для логистической регрессии\n",
    "print(best_params)\n",
    "\n",
    "# Оценим качество\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Вычисление F1-меры\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Вычисление ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T21:02:21.926341Z",
     "end_time": "2024-04-04T21:02:21.941977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Баланс классов в X_train_resampled:\n",
      "{0: 323, 1: 644}\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем количество элементов каждого класса в y_train_resampled\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Баланс классов в X_train_resampled:\")\n",
    "print(class_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T20:59:51.557751Z",
     "end_time": "2024-04-04T20:59:51.604328Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ДЕРЕВЬЯ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-04 15:40:41,997] A new study created in memory with name: no-name-fcc86695-7e92-4c5b-8b3f-c9408feebe7b\n",
      "[I 2024-04-04 15:40:42,015] Trial 0 finished with value: 0.7010752688172043 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 15}. Best is trial 0 with value: 0.7010752688172043.\n",
      "[I 2024-04-04 15:40:42,030] Trial 1 finished with value: 0.7598425196850394 and parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 16, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.7598425196850394.\n",
      "[I 2024-04-04 15:40:42,064] Trial 2 finished with value: 0.7516778523489934 and parameters: {'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 16, 'min_samples_leaf': 11}. Best is trial 1 with value: 0.7598425196850394.\n",
      "[I 2024-04-04 15:40:42,092] Trial 3 finished with value: 0.6968124536693847 and parameters: {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7598425196850394.\n",
      "[I 2024-04-04 15:40:42,098] Trial 4 finished with value: 0.7894406033940917 and parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.7894406033940917.\n",
      "[I 2024-04-04 15:40:42,113] Trial 5 finished with value: 0.7881462799495587 and parameters: {'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.7894406033940917.\n",
      "[I 2024-04-04 15:40:42,130] Trial 6 finished with value: 0.6997808619430241 and parameters: {'criterion': 'gini', 'max_depth': 31, 'min_samples_split': 8, 'min_samples_leaf': 12}. Best is trial 4 with value: 0.7894406033940917.\n",
      "[I 2024-04-04 15:40:42,156] Trial 7 finished with value: 0.7548430193720774 and parameters: {'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.7894406033940917.\n",
      "[I 2024-04-04 15:40:42,164] Trial 8 finished with value: 0.783817951959545 and parameters: {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 18}. Best is trial 4 with value: 0.7894406033940917.\n",
      "[I 2024-04-04 15:40:42,181] Trial 9 finished with value: 0.7258741258741259 and parameters: {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 12}. Best is trial 4 with value: 0.7894406033940917.\n",
      "[I 2024-04-04 15:40:42,231] Trial 10 finished with value: 0.7897049591964846 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.7897049591964846.\n",
      "[I 2024-04-04 15:40:42,246] Trial 11 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,263] Trial 12 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,296] Trial 13 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,326] Trial 14 finished with value: 0.7645536869340233 and parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,369] Trial 15 finished with value: 0.7265017667844523 and parameters: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,408] Trial 16 finished with value: 0.7853071564281191 and parameters: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,430] Trial 17 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 14, 'min_samples_leaf': 14}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,463] Trial 18 finished with value: 0.7576974564926373 and parameters: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 19, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,480] Trial 19 finished with value: 0.778557753669432 and parameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 18, 'min_samples_leaf': 19}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,535] Trial 20 finished with value: 0.6722689075630253 and parameters: {'criterion': 'entropy', 'max_depth': 32, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,546] Trial 21 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,580] Trial 22 finished with value: 0.7894406033940917 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,599] Trial 23 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,627] Trial 24 finished with value: 0.7860759493670887 and parameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,664] Trial 25 finished with value: 0.7284122562674095 and parameters: {'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,680] Trial 26 finished with value: 0.7894406033940917 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,730] Trial 27 finished with value: 0.692138133725202 and parameters: {'criterion': 'entropy', 'max_depth': 26, 'min_samples_split': 14, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,764] Trial 28 finished with value: 0.7438692098092643 and parameters: {'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 17, 'min_samples_leaf': 14}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,800] Trial 29 finished with value: 0.7791215786123488 and parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,830] Trial 30 finished with value: 0.7858496525584334 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 17}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,856] Trial 31 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 14, 'min_samples_leaf': 15}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,865] Trial 32 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 19, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,917] Trial 33 finished with value: 0.7871536523929472 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:42,980] Trial 34 finished with value: 0.7587113740959897 and parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 11}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,007] Trial 35 finished with value: 0.7858496525584334 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 16}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,030] Trial 36 finished with value: 0.789937106918239 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,063] Trial 37 finished with value: 0.778557753669432 and parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 20}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,097] Trial 38 finished with value: 0.7580213903743315 and parameters: {'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 16, 'min_samples_leaf': 12}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,130] Trial 39 finished with value: 0.6893995552260934 and parameters: {'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 15, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,158] Trial 40 finished with value: 0.7897049591964846 and parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,192] Trial 41 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,230] Trial 42 finished with value: 0.7894406033940917 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,247] Trial 43 finished with value: 0.7897049591964846 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,280] Trial 44 finished with value: 0.7894406033940917 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,314] Trial 45 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,347] Trial 46 finished with value: 0.789937106918239 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,380] Trial 47 finished with value: 0.6808834729626809 and parameters: {'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,414] Trial 48 finished with value: 0.7822222222222223 and parameters: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 19, 'min_samples_leaf': 11}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,464] Trial 49 finished with value: 0.7478025693035835 and parameters: {'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,491] Trial 50 finished with value: 0.7897049591964846 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,514] Trial 51 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,548] Trial 52 finished with value: 0.7879548306148054 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,664] Trial 53 finished with value: 0.6915750915750917 and parameters: {'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 13, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,701] Trial 54 finished with value: 0.7897049591964846 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,730] Trial 55 finished with value: 0.7894406033940917 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,763] Trial 56 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,801] Trial 57 finished with value: 0.7881462799495587 and parameters: {'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,864] Trial 58 finished with value: 0.7894736842105263 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,896] Trial 59 finished with value: 0.7806738715829624 and parameters: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 19, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,913] Trial 60 finished with value: 0.7874213836477988 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 13, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,942] Trial 61 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 12, 'min_samples_leaf': 16}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,963] Trial 62 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 16, 'min_samples_leaf': 14}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:43,980] Trial 63 finished with value: 0.7858496525584334 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 15}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,006] Trial 64 finished with value: 0.7874213836477988 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 14}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,030] Trial 65 finished with value: 0.7837666455294863 and parameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 18}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,064] Trial 66 finished with value: 0.7858496525584334 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 15}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,080] Trial 67 finished with value: 0.7861198738170347 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,114] Trial 68 finished with value: 0.7029348604151753 and parameters: {'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 20, 'min_samples_leaf': 17}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,147] Trial 69 finished with value: 0.7881462799495587 and parameters: {'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,175] Trial 70 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 19, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,206] Trial 71 finished with value: 0.7874213836477988 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,233] Trial 72 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 19, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,264] Trial 73 finished with value: 0.7894406033940917 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'min_samples_leaf': 12}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,280] Trial 74 finished with value: 0.7897049591964846 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 11}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,314] Trial 75 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 14, 'min_samples_leaf': 16}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,347] Trial 76 finished with value: 0.7881462799495587 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,374] Trial 77 finished with value: 0.7824984147114774 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 14}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,397] Trial 78 finished with value: 0.7914840325610519 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,431] Trial 79 finished with value: 0.7881462799495587 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,447] Trial 80 finished with value: 0.7957658779576587 and parameters: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 15}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,480] Trial 81 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,502] Trial 82 finished with value: 0.7897049591964846 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,530] Trial 83 finished with value: 0.7894406033940917 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,547] Trial 84 finished with value: 0.7881462799495587 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,581] Trial 85 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 12}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,602] Trial 86 finished with value: 0.7897049591964846 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,647] Trial 87 finished with value: 0.7421555252387448 and parameters: {'criterion': 'entropy', 'max_depth': 14, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,680] Trial 88 finished with value: 0.7889447236180904 and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,707] Trial 89 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,730] Trial 90 finished with value: 0.7848101265822786 and parameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,764] Trial 91 finished with value: 0.7897049591964846 and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,802] Trial 92 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,832] Trial 93 finished with value: 0.7881462799495587 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,863] Trial 94 finished with value: 0.6909620991253645 and parameters: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 18, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,897] Trial 95 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,925] Trial 96 finished with value: 0.7881462799495587 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,958] Trial 97 finished with value: 0.7897049591964846 and parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:44,981] Trial 98 finished with value: 0.7957658779576587 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 19, 'min_samples_leaf': 14}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:45,014] Trial 99 finished with value: 0.783817951959545 and parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:45,014] A new study created in memory with name: no-name-9f7ec49a-25db-49b5-ab77-7899329b812b\n",
      "[I 2024-04-04 15:40:45,813] Trial 0 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 102, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:48,264] Trial 1 finished with value: 0.7433264887063655 and parameters: {'n_estimators': 168, 'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:50,131] Trial 2 finished with value: 0.7768488745980706 and parameters: {'n_estimators': 177, 'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:50,763] Trial 3 finished with value: 0.7799871712636305 and parameters: {'n_estimators': 56, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 13, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:52,330] Trial 4 finished with value: 0.7635402906208718 and parameters: {'n_estimators': 127, 'criterion': 'entropy', 'max_depth': 28, 'min_samples_split': 9, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:53,307] Trial 5 finished with value: 0.7465940054495912 and parameters: {'n_estimators': 69, 'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:54,597] Trial 6 finished with value: 0.7503373819163293 and parameters: {'n_estimators': 70, 'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 20, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:55,913] Trial 7 finished with value: 0.7447243022464262 and parameters: {'n_estimators': 101, 'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:40:58,497] Trial 8 finished with value: 0.7591727818545697 and parameters: {'n_estimators': 186, 'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:00,478] Trial 9 finished with value: 0.7516778523489934 and parameters: {'n_estimators': 131, 'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:00,897] Trial 10 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 99, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:01,246] Trial 11 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 97, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:01,580] Trial 12 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 101, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:02,763] Trial 13 finished with value: 0.79375 and parameters: {'n_estimators': 147, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:03,474] Trial 14 finished with value: 0.7950155763239874 and parameters: {'n_estimators': 92, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:04,413] Trial 15 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 115, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:05,568] Trial 16 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 147, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:06,446] Trial 17 finished with value: 0.7844387755102041 and parameters: {'n_estimators': 82, 'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 20}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:06,917] Trial 18 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 113, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 15}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:07,529] Trial 19 finished with value: 0.784586228679722 and parameters: {'n_estimators': 51, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:09,179] Trial 20 finished with value: 0.7660130718954248 and parameters: {'n_estimators': 141, 'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 20, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:09,673] Trial 21 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 84, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:10,413] Trial 22 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 111, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:10,779] Trial 23 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 96, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:11,646] Trial 24 finished with value: 0.7924764890282132 and parameters: {'n_estimators': 71, 'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:12,430] Trial 25 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 118, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:12,997] Trial 26 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 83, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:13,847] Trial 27 finished with value: 0.792995622263915 and parameters: {'n_estimators': 105, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:15,655] Trial 28 finished with value: 0.7657068062827225 and parameters: {'n_estimators': 132, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:17,890] Trial 29 finished with value: 0.7417127071823204 and parameters: {'n_estimators': 159, 'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 18, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:18,410] Trial 30 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 122, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:18,780] Trial 31 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 90, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:19,346] Trial 32 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 103, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:20,152] Trial 33 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 105, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 19, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:20,980] Trial 34 finished with value: 0.7878787878787878 and parameters: {'n_estimators': 78, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:21,379] Trial 35 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 64, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:22,880] Trial 36 finished with value: 0.7377838953888507 and parameters: {'n_estimators': 95, 'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 9, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:23,613] Trial 37 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 108, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:25,396] Trial 38 finished with value: 0.7911949685534592 and parameters: {'n_estimators': 124, 'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:26,363] Trial 39 finished with value: 0.7436074637180373 and parameters: {'n_estimators': 63, 'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:29,346] Trial 40 finished with value: 0.7538772757923128 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 32, 'min_samples_split': 6, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:30,467] Trial 41 finished with value: 0.793512164691204 and parameters: {'n_estimators': 117, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:30,956] Trial 42 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 99, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:31,679] Trial 43 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 89, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:33,605] Trial 44 finished with value: 0.7397260273972602 and parameters: {'n_estimators': 135, 'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:34,247] Trial 45 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 115, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:34,913] Trial 46 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 76, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:35,396] Trial 47 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:36,176] Trial 48 finished with value: 0.79375 and parameters: {'n_estimators': 89, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:37,079] Trial 49 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 126, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:37,563] Trial 50 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 111, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 11, 'min_samples_leaf': 15}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:38,763] Trial 51 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 158, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:39,329] Trial 52 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 148, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:41,029] Trial 53 finished with value: 0.7917448405253283 and parameters: {'n_estimators': 166, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:42,330] Trial 54 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 180, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 19, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:43,113] Trial 55 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 143, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 15}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:43,563] Trial 56 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 121, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:44,307] Trial 57 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 109, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:45,196] Trial 58 finished with value: 0.792995622263915 and parameters: {'n_estimators': 97, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:46,897] Trial 59 finished with value: 0.7643564356435645 and parameters: {'n_estimators': 134, 'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 16, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:47,896] Trial 60 finished with value: 0.7836630504148054 and parameters: {'n_estimators': 85, 'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:48,412] Trial 61 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 115, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:48,763] Trial 62 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 104, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 20}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:49,246] Trial 63 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 93, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 15}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:50,013] Trial 64 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 129, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:50,529] Trial 65 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 112, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:50,879] Trial 66 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 101, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:51,850] Trial 67 finished with value: 0.7950155763239874 and parameters: {'n_estimators': 120, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:52,592] Trial 68 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 107, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:53,563] Trial 69 finished with value: 0.7919799498746867 and parameters: {'n_estimators': 87, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:54,279] Trial 70 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 95, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 15}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:54,719] Trial 71 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 77, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:55,163] Trial 72 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 84, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:55,773] Trial 73 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 93, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:56,163] Trial 74 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 113, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:56,959] Trial 75 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 80, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:58,084] Trial 76 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 74, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:41:59,140] Trial 77 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 103, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:00,989] Trial 78 finished with value: 0.7942643391521197 and parameters: {'n_estimators': 99, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:02,407] Trial 79 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 107, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:06,078] Trial 80 finished with value: 0.7483085250338295 and parameters: {'n_estimators': 118, 'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 18, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:06,981] Trial 81 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 125, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:08,229] Trial 82 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 110, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:10,668] Trial 83 finished with value: 0.7942643391521197 and parameters: {'n_estimators': 138, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:11,635] Trial 84 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 98, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:13,333] Trial 85 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 115, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:14,524] Trial 86 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 91, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:15,105] Trial 87 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 66, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:16,236] Trial 88 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 102, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:18,696] Trial 89 finished with value: 0.7642384105960266 and parameters: {'n_estimators': 107, 'criterion': 'gini', 'max_depth': 23, 'min_samples_split': 13, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:21,870] Trial 90 finished with value: 0.773109243697479 and parameters: {'n_estimators': 122, 'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 19}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:22,790] Trial 91 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 95, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:24,217] Trial 92 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 153, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:24,982] Trial 93 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 89, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:26,365] Trial 94 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 103, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:27,337] Trial 95 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 82, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:29,264] Trial 96 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 129, 'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:30,186] Trial 97 finished with value: 0.7957658779576587 and parameters: {'n_estimators': 111, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 13}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:31,672] Trial 98 finished with value: 0.7940074906367042 and parameters: {'n_estimators': 86, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 15}. Best is trial 0 with value: 0.7957658779576587.\n",
      "[I 2024-04-04 15:42:33,644] Trial 99 finished with value: 0.7927363807138385 and parameters: {'n_estimators': 106, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 11}. Best is trial 0 with value: 0.7957658779576587.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Decision Tree: 0.80\n",
      "F1 Score for Random Forest: 0.80\n",
      "accuracy_dt: 0.66\n",
      "accuracy_rf: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "\n",
    "# Функция для оптимизации гиперпараметров модели Decision Tree\n",
    "def objective_dt(trial):\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
    "\n",
    "    model = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    return f1\n",
    "\n",
    "# Функция для оптимизации гиперпараметров модели Random Forest\n",
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    return f1\n",
    "\n",
    "# Оптимизация гиперпараметров для модели Decision Tree\n",
    "study_dt = optuna.create_study(direction=\"maximize\")\n",
    "study_dt.optimize(objective_dt, n_trials=100)\n",
    "\n",
    "# Оптимизация гиперпараметров для модели Random Forest\n",
    "study_rf = optuna.create_study(direction=\"maximize\")\n",
    "study_rf.optimize(objective_rf, n_trials=100)\n",
    "\n",
    "# Получение лучших гиперпараметров для Decision Tree\n",
    "best_params_dt = study_dt.best_params\n",
    "\n",
    "# Получение лучших гиперпараметров для Random Forest\n",
    "best_params_rf = study_rf.best_params\n",
    "\n",
    "# Создание моделей с лучшими гиперпараметрами\n",
    "best_model_dt = DecisionTreeClassifier(**best_params_dt)\n",
    "best_model_rf = RandomForestClassifier(**best_params_rf)\n",
    "\n",
    "# Обучение моделей\n",
    "best_model_dt.fit(X_train, y_train)\n",
    "best_model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Оценка качества моделей\n",
    "y_pred_dt = best_model_dt.predict(X_test)\n",
    "y_pred_rf = best_model_rf.predict(X_test)\n",
    "\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "\n",
    "print(f\"F1 Score for Decision Tree: {f1_dt:.2f}\")\n",
    "print(f\"F1 Score for Random Forest: {f1_rf:.2f}\")\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"accuracy_dt: {accuracy_dt:.2f}\")\n",
    "print(f\"accuracy_rf: {accuracy_rf:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T15:40:41.999459Z",
     "end_time": "2024-04-04T15:42:34.910296Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# catboost\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-04 21:05:48,058] A new study created in memory with name: no-name-e52c390d-14c0-41cd-b6db-3c521c1f0a69\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:05:51,391] Trial 0 finished with value: 0.607725321888412 and parameters: {'iterations': 750, 'learning_rate': 0.07899904730769812, 'depth': 9, 'l2_leaf_reg': 0.02124935741447255, 'border_count': 153, 'random_strength': 0.030431252896149317, 'bagging_temperature': 0.032558277592766034, 'min_data_in_leaf': 14, 'leaf_estimation_iterations': 7, 'leaf_estimation_method': 'Newton'}. Best is trial 0 with value: 0.607725321888412.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:05:52,102] Trial 1 finished with value: 0.494908350305499 and parameters: {'iterations': 202, 'learning_rate': 0.0031338802001898572, 'depth': 8, 'l2_leaf_reg': 0.8958396988592595, 'border_count': 107, 'random_strength': 0.2109944360604313, 'bagging_temperature': 0.061135581436609424, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 10, 'leaf_estimation_method': 'Newton'}. Best is trial 0 with value: 0.607725321888412.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:05:52,511] Trial 2 finished with value: 0.5690759377859104 and parameters: {'iterations': 158, 'learning_rate': 0.04483035954217814, 'depth': 5, 'l2_leaf_reg': 1.1950312065561743, 'border_count': 244, 'random_strength': 0.0014113468223267518, 'bagging_temperature': 8.816547464477164, 'min_data_in_leaf': 19, 'leaf_estimation_iterations': 5, 'leaf_estimation_method': 'Gradient'}. Best is trial 0 with value: 0.607725321888412.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:05:53,627] Trial 3 finished with value: 0.45250800426894344 and parameters: {'iterations': 349, 'learning_rate': 0.0013476648525902796, 'depth': 9, 'l2_leaf_reg': 0.0017471077172504235, 'border_count': 85, 'random_strength': 7.816321797460701, 'bagging_temperature': 4.743087284179737, 'min_data_in_leaf': 1, 'leaf_estimation_iterations': 10, 'leaf_estimation_method': 'Newton'}. Best is trial 0 with value: 0.607725321888412.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:05:54,705] Trial 4 finished with value: 0.6017543859649124 and parameters: {'iterations': 324, 'learning_rate': 0.08265574016842435, 'depth': 8, 'l2_leaf_reg': 0.11756484587616814, 'border_count': 209, 'random_strength': 2.367050609649855, 'bagging_temperature': 0.0014889972539997313, 'min_data_in_leaf': 12, 'leaf_estimation_iterations': 2, 'leaf_estimation_method': 'Gradient'}. Best is trial 0 with value: 0.607725321888412.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:05:56,152] Trial 5 finished with value: 0.5502846299810246 and parameters: {'iterations': 833, 'learning_rate': 0.00749512820279841, 'depth': 4, 'l2_leaf_reg': 3.633233972255943, 'border_count': 85, 'random_strength': 0.030438840207802166, 'bagging_temperature': 0.030661877454739302, 'min_data_in_leaf': 16, 'leaf_estimation_iterations': 7, 'leaf_estimation_method': 'Gradient'}. Best is trial 0 with value: 0.607725321888412.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:05:56,675] Trial 6 finished with value: 0.6040034812880767 and parameters: {'iterations': 355, 'learning_rate': 0.06184813406934587, 'depth': 3, 'l2_leaf_reg': 0.10398774872153974, 'border_count': 237, 'random_strength': 0.013734250156719635, 'bagging_temperature': 0.003973457663511062, 'min_data_in_leaf': 17, 'leaf_estimation_iterations': 2, 'leaf_estimation_method': 'Newton'}. Best is trial 0 with value: 0.607725321888412.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:05:59,007] Trial 7 finished with value: 0.4984984984984984 and parameters: {'iterations': 247, 'learning_rate': 0.0023121385382732494, 'depth': 10, 'l2_leaf_reg': 0.003474559852411056, 'border_count': 217, 'random_strength': 0.015528308113339653, 'bagging_temperature': 0.6048554732498411, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 4, 'leaf_estimation_method': 'Newton'}. Best is trial 0 with value: 0.607725321888412.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:02,211] Trial 8 finished with value: 0.5735294117647058 and parameters: {'iterations': 918, 'learning_rate': 0.007379624399983681, 'depth': 9, 'l2_leaf_reg': 0.45199129589194165, 'border_count': 58, 'random_strength': 0.00562811326995857, 'bagging_temperature': 1.085715544125465, 'min_data_in_leaf': 12, 'leaf_estimation_iterations': 8, 'leaf_estimation_method': 'Newton'}. Best is trial 0 with value: 0.607725321888412.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:03,097] Trial 9 finished with value: 0.6077922077922078 and parameters: {'iterations': 418, 'learning_rate': 0.08088203414376118, 'depth': 6, 'l2_leaf_reg': 0.02710760690917022, 'border_count': 192, 'random_strength': 0.17911508591848455, 'bagging_temperature': 9.524617500823927, 'min_data_in_leaf': 5, 'leaf_estimation_iterations': 4, 'leaf_estimation_method': 'Gradient'}. Best is trial 9 with value: 0.6077922077922078.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:04,000] Trial 10 finished with value: 0.5445920303605313 and parameters: {'iterations': 567, 'learning_rate': 0.025446320784483566, 'depth': 6, 'l2_leaf_reg': 0.010769610129282282, 'border_count': 167, 'random_strength': 0.2233759341695392, 'bagging_temperature': 0.8230187091414507, 'min_data_in_leaf': 7, 'leaf_estimation_iterations': 1, 'leaf_estimation_method': 'Gradient'}. Best is trial 9 with value: 0.6077922077922078.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:05,677] Trial 11 finished with value: 0.6060085836909871 and parameters: {'iterations': 640, 'learning_rate': 0.09819994195025408, 'depth': 7, 'l2_leaf_reg': 0.016460321893948655, 'border_count': 160, 'random_strength': 0.09843211767274569, 'bagging_temperature': 0.1706831064299538, 'min_data_in_leaf': 8, 'leaf_estimation_iterations': 7, 'leaf_estimation_method': 'Gradient'}. Best is trial 9 with value: 0.6077922077922078.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:07,168] Trial 12 finished with value: 0.5709057639524245 and parameters: {'iterations': 725, 'learning_rate': 0.018118028964316055, 'depth': 6, 'l2_leaf_reg': 0.028770979243211717, 'border_count': 180, 'random_strength': 0.0795631830959224, 'bagging_temperature': 0.01668737371921174, 'min_data_in_leaf': 9, 'leaf_estimation_iterations': 5, 'leaf_estimation_method': 'Gradient'}. Best is trial 9 with value: 0.6077922077922078.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:08,363] Trial 13 finished with value: 0.6003490401396161 and parameters: {'iterations': 474, 'learning_rate': 0.03759116817541736, 'depth': 7, 'l2_leaf_reg': 0.04207271221376373, 'border_count': 127, 'random_strength': 0.5367705905594362, 'bagging_temperature': 0.18036144236887003, 'min_data_in_leaf': 15, 'leaf_estimation_iterations': 4, 'leaf_estimation_method': 'Newton'}. Best is trial 9 with value: 0.6077922077922078.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:09,766] Trial 14 finished with value: 0.6151202749140893 and parameters: {'iterations': 728, 'learning_rate': 0.04664651300001168, 'depth': 5, 'l2_leaf_reg': 0.005199565349897735, 'border_count': 194, 'random_strength': 0.6711429424695191, 'bagging_temperature': 0.011200631084848733, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 7, 'leaf_estimation_method': 'Newton'}. Best is trial 14 with value: 0.6151202749140893.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:10,605] Trial 15 finished with value: 0.5947888589398023 and parameters: {'iterations': 507, 'learning_rate': 0.03418850661191055, 'depth': 5, 'l2_leaf_reg': 0.004661826192291941, 'border_count': 194, 'random_strength': 1.131671062297973, 'bagging_temperature': 0.006992721009467938, 'min_data_in_leaf': 5, 'leaf_estimation_iterations': 3, 'leaf_estimation_method': 'Gradient'}. Best is trial 14 with value: 0.6151202749140893.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:11,749] Trial 16 finished with value: 0.6066433566433567 and parameters: {'iterations': 646, 'learning_rate': 0.02071212822511796, 'depth': 4, 'l2_leaf_reg': 0.0011884192303790316, 'border_count': 255, 'random_strength': 0.4812308352756803, 'bagging_temperature': 2.8953662746974405, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 8, 'leaf_estimation_method': 'Newton'}. Best is trial 14 with value: 0.6151202749140893.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:12,646] Trial 17 finished with value: 0.5788999098286745 and parameters: {'iterations': 445, 'learning_rate': 0.054206172533131834, 'depth': 5, 'l2_leaf_reg': 0.007423162768938676, 'border_count': 198, 'random_strength': 2.5085062378649616, 'bagging_temperature': 9.681508635783299, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 6, 'leaf_estimation_method': 'Gradient'}. Best is trial 14 with value: 0.6151202749140893.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:14,405] Trial 18 finished with value: 0.5755919854280509 and parameters: {'iterations': 980, 'learning_rate': 0.013914633495867428, 'depth': 3, 'l2_leaf_reg': 0.0038275230270610585, 'border_count': 131, 'random_strength': 0.25436046108001353, 'bagging_temperature': 0.3137270903039595, 'min_data_in_leaf': 10, 'leaf_estimation_iterations': 9, 'leaf_estimation_method': 'Gradient'}. Best is trial 14 with value: 0.6151202749140893.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:16,222] Trial 19 finished with value: 0.6136560069144338 and parameters: {'iterations': 817, 'learning_rate': 0.05120895835352691, 'depth': 6, 'l2_leaf_reg': 0.05216502424647463, 'border_count': 215, 'random_strength': 0.9427706502810624, 'bagging_temperature': 0.08407308319324115, 'min_data_in_leaf': 2, 'leaf_estimation_iterations': 6, 'leaf_estimation_method': 'Newton'}. Best is trial 14 with value: 0.6151202749140893.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:17,580] Trial 20 finished with value: 0.588967971530249 and parameters: {'iterations': 844, 'learning_rate': 0.03045179352328384, 'depth': 4, 'l2_leaf_reg': 0.05396758268527675, 'border_count': 220, 'random_strength': 9.767198735973327, 'bagging_temperature': 0.06982804683749384, 'min_data_in_leaf': 3, 'leaf_estimation_iterations': 6, 'leaf_estimation_method': 'Newton'}. Best is trial 14 with value: 0.6151202749140893.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:19,172] Trial 21 finished with value: 0.5961199294532629 and parameters: {'iterations': 731, 'learning_rate': 0.05484208333488579, 'depth': 6, 'l2_leaf_reg': 0.010915916059638802, 'border_count': 187, 'random_strength': 0.6921964702008984, 'bagging_temperature': 0.10012510762631578, 'min_data_in_leaf': 2, 'leaf_estimation_iterations': 4, 'leaf_estimation_method': 'Newton'}. Best is trial 14 with value: 0.6151202749140893.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:21,522] Trial 22 finished with value: 0.6144578313253013 and parameters: {'iterations': 843, 'learning_rate': 0.04382669121979818, 'depth': 7, 'l2_leaf_reg': 0.05695652459898688, 'border_count': 228, 'random_strength': 1.1718605003118352, 'bagging_temperature': 2.1233185974968087, 'min_data_in_leaf': 6, 'leaf_estimation_iterations': 6, 'leaf_estimation_method': 'Newton'}. Best is trial 14 with value: 0.6151202749140893.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:23,704] Trial 23 finished with value: 0.6188034188034188 and parameters: {'iterations': 839, 'learning_rate': 0.03971115138339135, 'depth': 7, 'l2_leaf_reg': 0.1661240327092717, 'border_count': 220, 'random_strength': 1.5398138748066088, 'bagging_temperature': 2.0179086431558995, 'min_data_in_leaf': 7, 'leaf_estimation_iterations': 6, 'leaf_estimation_method': 'Newton'}. Best is trial 23 with value: 0.6188034188034188.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:26,410] Trial 24 finished with value: 0.6206896551724138 and parameters: {'iterations': 923, 'learning_rate': 0.030316944380044276, 'depth': 7, 'l2_leaf_reg': 0.2298255910291456, 'border_count': 229, 'random_strength': 1.8489263725112397, 'bagging_temperature': 1.839823614613387, 'min_data_in_leaf': 7, 'leaf_estimation_iterations': 8, 'leaf_estimation_method': 'Newton'}. Best is trial 24 with value: 0.6206896551724138.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:30,020] Trial 25 finished with value: 0.6157760814249365 and parameters: {'iterations': 933, 'learning_rate': 0.03224313013408832, 'depth': 8, 'l2_leaf_reg': 0.20782941230184965, 'border_count': 252, 'random_strength': 3.4154601437081165, 'bagging_temperature': 1.8001761419234341, 'min_data_in_leaf': 8, 'leaf_estimation_iterations': 8, 'leaf_estimation_method': 'Newton'}. Best is trial 24 with value: 0.6206896551724138.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:34,056] Trial 26 finished with value: 0.6106346483704974 and parameters: {'iterations': 986, 'learning_rate': 0.028347339874574908, 'depth': 8, 'l2_leaf_reg': 0.22804577824240027, 'border_count': 250, 'random_strength': 4.63193392601317, 'bagging_temperature': 1.5103020756916101, 'min_data_in_leaf': 11, 'leaf_estimation_iterations': 9, 'leaf_estimation_method': 'Newton'}. Best is trial 24 with value: 0.6206896551724138.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:37,746] Trial 27 finished with value: 0.6087719298245615 and parameters: {'iterations': 918, 'learning_rate': 0.015588572477886106, 'depth': 8, 'l2_leaf_reg': 0.21147071048322044, 'border_count': 234, 'random_strength': 2.5902281072061952, 'bagging_temperature': 0.4578757338498549, 'min_data_in_leaf': 8, 'leaf_estimation_iterations': 8, 'leaf_estimation_method': 'Newton'}. Best is trial 24 with value: 0.6206896551724138.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:47,757] Trial 28 finished with value: 0.6137931034482759 and parameters: {'iterations': 902, 'learning_rate': 0.02385508517620382, 'depth': 10, 'l2_leaf_reg': 0.23027596013046286, 'border_count': 236, 'random_strength': 3.614563187376959, 'bagging_temperature': 3.5704678021478253, 'min_data_in_leaf': 10, 'leaf_estimation_iterations': 8, 'leaf_estimation_method': 'Newton'}. Best is trial 24 with value: 0.6206896551724138.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:50,747] Trial 29 finished with value: 0.5377176015473888 and parameters: {'iterations': 779, 'learning_rate': 0.011139871775948417, 'depth': 7, 'l2_leaf_reg': 0.43243361394113167, 'border_count': 172, 'random_strength': 1.7727602802905251, 'bagging_temperature': 1.3659481322267124, 'min_data_in_leaf': 13, 'leaf_estimation_iterations': 9, 'leaf_estimation_method': 'Newton'}. Best is trial 24 with value: 0.6206896551724138.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:53,833] Trial 30 finished with value: 0.5977410947002607 and parameters: {'iterations': 666, 'learning_rate': 0.030527713623992314, 'depth': 9, 'l2_leaf_reg': 0.09997051764518682, 'border_count': 147, 'random_strength': 5.3801192122682515, 'bagging_temperature': 1.975109866995128, 'min_data_in_leaf': 8, 'leaf_estimation_iterations': 9, 'leaf_estimation_method': 'Newton'}. Best is trial 24 with value: 0.6206896551724138.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:57,146] Trial 31 finished with value: 0.5975395430579964 and parameters: {'iterations': 893, 'learning_rate': 0.07013225970326152, 'depth': 8, 'l2_leaf_reg': 0.019161125100249813, 'border_count': 204, 'random_strength': 1.5032671639804187, 'bagging_temperature': 0.8971035588106667, 'min_data_in_leaf': 7, 'leaf_estimation_iterations': 7, 'leaf_estimation_method': 'Newton'}. Best is trial 24 with value: 0.6206896551724138.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:06:59,509] Trial 32 finished with value: 0.6181506849315069 and parameters: {'iterations': 770, 'learning_rate': 0.046007420477132056, 'depth': 7, 'l2_leaf_reg': 0.12787733586967057, 'border_count': 227, 'random_strength': 3.8873547739255336, 'bagging_temperature': 0.5507614334567129, 'min_data_in_leaf': 9, 'leaf_estimation_iterations': 7, 'leaf_estimation_method': 'Newton'}. Best is trial 24 with value: 0.6206896551724138.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:02,399] Trial 33 finished with value: 0.6222222222222222 and parameters: {'iterations': 953, 'learning_rate': 0.0382281337292051, 'depth': 7, 'l2_leaf_reg': 0.903722796854898, 'border_count': 223, 'random_strength': 4.243504199010077, 'bagging_temperature': 4.345097527845034, 'min_data_in_leaf': 9, 'leaf_estimation_iterations': 8, 'leaf_estimation_method': 'Newton'}. Best is trial 33 with value: 0.6222222222222222.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:05,481] Trial 34 finished with value: 0.6111111111111112 and parameters: {'iterations': 1000, 'learning_rate': 0.037595968431211775, 'depth': 7, 'l2_leaf_reg': 1.178619425950861, 'border_count': 224, 'random_strength': 6.557009398413835, 'bagging_temperature': 4.1459576269908105, 'min_data_in_leaf': 10, 'leaf_estimation_iterations': 10, 'leaf_estimation_method': 'Newton'}. Best is trial 33 with value: 0.6222222222222222.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:07,987] Trial 35 finished with value: 0.6173688736027515 and parameters: {'iterations': 797, 'learning_rate': 0.06473083503578178, 'depth': 7, 'l2_leaf_reg': 2.217529258366747, 'border_count': 241, 'random_strength': 8.825599474978219, 'bagging_temperature': 5.540445735156851, 'min_data_in_leaf': 9, 'leaf_estimation_iterations': 7, 'leaf_estimation_method': 'Newton'}. Best is trial 33 with value: 0.6222222222222222.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:10,301] Trial 36 finished with value: 0.612987012987013 and parameters: {'iterations': 874, 'learning_rate': 0.02182975040317817, 'depth': 7, 'l2_leaf_reg': 0.6759436578974477, 'border_count': 208, 'random_strength': 4.9378661260734, 'bagging_temperature': 2.4486440702733017, 'min_data_in_leaf': 12, 'leaf_estimation_iterations': 5, 'leaf_estimation_method': 'Newton'}. Best is trial 33 with value: 0.6222222222222222.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:13,894] Trial 37 finished with value: 0.6185567010309277 and parameters: {'iterations': 959, 'learning_rate': 0.04183002320598516, 'depth': 8, 'l2_leaf_reg': 7.035024377695984, 'border_count': 223, 'random_strength': 2.3882724860202043, 'bagging_temperature': 6.277074159242825, 'min_data_in_leaf': 11, 'leaf_estimation_iterations': 7, 'leaf_estimation_method': 'Newton'}. Best is trial 33 with value: 0.6222222222222222.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:16,633] Trial 38 finished with value: 0.562043795620438 and parameters: {'iterations': 939, 'learning_rate': 0.09526504720162633, 'depth': 8, 'l2_leaf_reg': 9.217808995918443, 'border_count': 103, 'random_strength': 2.1307901899047166, 'bagging_temperature': 5.527596667722611, 'min_data_in_leaf': 14, 'leaf_estimation_iterations': 6, 'leaf_estimation_method': 'Newton'}. Best is trial 33 with value: 0.6222222222222222.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:19,257] Trial 39 finished with value: 0.62248322147651 and parameters: {'iterations': 969, 'learning_rate': 0.03937439451539567, 'depth': 9, 'l2_leaf_reg': 1.8918048468735111, 'border_count': 35, 'random_strength': 1.6209542874331568, 'bagging_temperature': 5.861830560916771, 'min_data_in_leaf': 20, 'leaf_estimation_iterations': 5, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:19,643] Trial 40 finished with value: 0.5598526703499079 and parameters: {'iterations': 121, 'learning_rate': 0.06759734095609016, 'depth': 9, 'l2_leaf_reg': 1.9789158402027687, 'border_count': 46, 'random_strength': 1.3147008538140963, 'bagging_temperature': 4.240968348053222, 'min_data_in_leaf': 17, 'leaf_estimation_iterations': 3, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:23,446] Trial 41 finished with value: 0.5570776255707762 and parameters: {'iterations': 976, 'learning_rate': 0.036098994644113584, 'depth': 10, 'l2_leaf_reg': 4.759268618610769, 'border_count': 64, 'random_strength': 2.4607715112352726, 'bagging_temperature': 6.491171529763134, 'min_data_in_leaf': 7, 'leaf_estimation_iterations': 5, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:26,649] Trial 42 finished with value: 0.5798394290811775 and parameters: {'iterations': 951, 'learning_rate': 0.02564229824320448, 'depth': 9, 'l2_leaf_reg': 0.9772751935561667, 'border_count': 90, 'random_strength': 1.7566545467365091, 'bagging_temperature': 2.8709440685745067, 'min_data_in_leaf': 18, 'leaf_estimation_iterations': 5, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:28,785] Trial 43 finished with value: 0.6052855924978686 and parameters: {'iterations': 860, 'learning_rate': 0.042402018201975145, 'depth': 8, 'l2_leaf_reg': 1.7178244812480323, 'border_count': 33, 'random_strength': 7.010649888578127, 'bagging_temperature': 6.662165162791585, 'min_data_in_leaf': 20, 'leaf_estimation_iterations': 8, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:32,089] Trial 44 finished with value: 0.6061135371179039 and parameters: {'iterations': 883, 'learning_rate': 0.05847698716361749, 'depth': 8, 'l2_leaf_reg': 3.298871451815963, 'border_count': 211, 'random_strength': 0.8299983737751733, 'bagging_temperature': 9.317334353700026, 'min_data_in_leaf': 11, 'leaf_estimation_iterations': 7, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:34,526] Trial 45 finished with value: 0.605424321959755 and parameters: {'iterations': 953, 'learning_rate': 0.019958515941536383, 'depth': 6, 'l2_leaf_reg': 0.6270728468301789, 'border_count': 245, 'random_strength': 3.2056545657707063, 'bagging_temperature': 3.735212664187397, 'min_data_in_leaf': 14, 'leaf_estimation_iterations': 10, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:37,748] Trial 46 finished with value: 0.5542388331814039 and parameters: {'iterations': 998, 'learning_rate': 0.0742108850671727, 'depth': 9, 'l2_leaf_reg': 1.451321609565404, 'border_count': 69, 'random_strength': 1.8202685797052651, 'bagging_temperature': 1.234274619182985, 'min_data_in_leaf': 20, 'leaf_estimation_iterations': 6, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:44,753] Trial 47 finished with value: 0.5998240985048372 and parameters: {'iterations': 812, 'learning_rate': 0.02604063374684715, 'depth': 10, 'l2_leaf_reg': 0.41044873907498525, 'border_count': 180, 'random_strength': 0.34720615408885125, 'bagging_temperature': 2.768026074921538, 'min_data_in_leaf': 5, 'leaf_estimation_iterations': 8, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:45,445] Trial 48 finished with value: 0.5867393278837421 and parameters: {'iterations': 247, 'learning_rate': 0.040150208476871334, 'depth': 7, 'l2_leaf_reg': 0.8410601780159678, 'border_count': 122, 'random_strength': 0.972585437653614, 'bagging_temperature': 7.030771133170773, 'min_data_in_leaf': 16, 'leaf_estimation_iterations': 9, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3533341166.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
      "[I 2024-04-04 21:07:48,965] Trial 49 finished with value: 0.605424321959755 and parameters: {'iterations': 912, 'learning_rate': 0.0513387362565823, 'depth': 8, 'l2_leaf_reg': 5.250209372043568, 'border_count': 202, 'random_strength': 5.97734478547063, 'bagging_temperature': 0.8458480846282651, 'min_data_in_leaf': 4, 'leaf_estimation_iterations': 7, 'leaf_estimation_method': 'Newton'}. Best is trial 39 with value: 0.62248322147651.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for CatBoost: 0.62\n",
      "F1 Score for CatBoost: 0.62\n",
      "accuracy CatBoost:: 0.53\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "\n",
    "# Определение функции для оптимизации гиперпараметров CatBoost\n",
    "def objective_cb(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"random_strength\": trial.suggest_loguniform(\"random_strength\", 1e-3, 10),\n",
    "        \"bagging_temperature\": trial.suggest_loguniform(\"bagging_temperature\", 1e-3, 10),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 20),\n",
    "        \"leaf_estimation_iterations\": trial.suggest_int(\"leaf_estimation_iterations\", 1, 10),\n",
    "        \"leaf_estimation_method\": trial.suggest_categorical(\"leaf_estimation_method\", [\"Newton\", \"Gradient\"]),\n",
    "        \"boosting_type\": \"Plain\"  # Не стохастический бустинг для ускорения обучения\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return f1\n",
    "    # return roc_auc\n",
    "\n",
    "\n",
    "# Оптимизация гиперпараметров для CatBoost\n",
    "study_cb = optuna.create_study(direction=\"maximize\")\n",
    "study_cb.optimize(objective_cb, n_trials=50)\n",
    "\n",
    "# Получение лучших гиперпараметров для CatBoost\n",
    "best_params_cb = study_cb.best_params\n",
    "\n",
    "# Создание модели с лучшими гиперпараметрами\n",
    "best_model_cb = CatBoostClassifier(**best_params_cb)\n",
    "\n",
    "# Обучение модели\n",
    "best_model_cb.fit(X_train, y_train, verbose=0)\n",
    "\n",
    "# Оценка качества модели\n",
    "y_pred_cb = best_model_cb.predict(X_test)\n",
    "f1_cb = f1_score(y_test, y_pred_cb)\n",
    "\n",
    "print(f\"F1 Score for CatBoost: {f1_cb:.2f}\")\n",
    "print(f\"F1 Score for CatBoost: {f1_cb:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_cb)\n",
    "print(f\"accuracy CatBoost:: {accuracy :.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T21:05:48.073731Z",
     "end_time": "2024-04-04T21:07:51.493650Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# АНСАМБЛИ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-04 21:12:41,788] A new study created in memory with name: no-name-9d108f0d-921b-40fc-8bdb-deadfe60e81e\n",
      "[I 2024-04-04 21:12:45,956] Trial 0 finished with value: 0.516028955532575 and parameters: {'n_estimators': 136, 'criterion': 'entropy', 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.516028955532575.\n",
      "[I 2024-04-04 21:12:47,518] Trial 1 finished with value: 0.5274043433298863 and parameters: {'n_estimators': 69, 'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 16, 'min_samples_leaf': 16}. Best is trial 1 with value: 0.5274043433298863.\n",
      "[I 2024-04-04 21:12:50,898] Trial 2 finished with value: 0.5098241985522234 and parameters: {'n_estimators': 160, 'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 18, 'min_samples_leaf': 12}. Best is trial 1 with value: 0.5274043433298863.\n",
      "[I 2024-04-04 21:12:51,439] Trial 3 finished with value: 0.4643226473629783 and parameters: {'n_estimators': 71, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.5274043433298863.\n",
      "[I 2024-04-04 21:12:53,369] Trial 4 finished with value: 0.5077559462254395 and parameters: {'n_estimators': 137, 'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.5274043433298863.\n",
      "[I 2024-04-04 21:12:54,969] Trial 5 finished with value: 0.500517063081696 and parameters: {'n_estimators': 166, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 11}. Best is trial 1 with value: 0.5274043433298863.\n",
      "[I 2024-04-04 21:12:57,286] Trial 6 finished with value: 0.5284384694932782 and parameters: {'n_estimators': 136, 'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 17, 'min_samples_leaf': 15}. Best is trial 6 with value: 0.5284384694932782.\n",
      "[I 2024-04-04 21:12:57,623] Trial 7 finished with value: 0.4095139607032058 and parameters: {'n_estimators': 78, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.5284384694932782.\n",
      "[I 2024-04-04 21:13:01,206] Trial 8 finished with value: 0.5222337125129266 and parameters: {'n_estimators': 175, 'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 12, 'min_samples_leaf': 13}. Best is trial 6 with value: 0.5284384694932782.\n",
      "[I 2024-04-04 21:13:03,787] Trial 9 finished with value: 0.49120992761116855 and parameters: {'n_estimators': 186, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 11}. Best is trial 6 with value: 0.5284384694932782.\n",
      "[I 2024-04-04 21:13:05,640] Trial 10 finished with value: 0.5387797311271976 and parameters: {'n_estimators': 117, 'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 13, 'min_samples_leaf': 20}. Best is trial 10 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:13:07,892] Trial 11 finished with value: 0.5274043433298863 and parameters: {'n_estimators': 105, 'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 13, 'min_samples_leaf': 20}. Best is trial 10 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:13:09,920] Trial 12 finished with value: 0.5336091003102379 and parameters: {'n_estimators': 110, 'criterion': 'entropy', 'max_depth': 32, 'min_samples_split': 14, 'min_samples_leaf': 19}. Best is trial 10 with value: 0.5387797311271976.\n",
      "[I 2024-04-04 21:13:11,928] Trial 13 finished with value: 0.5511892450879007 and parameters: {'n_estimators': 103, 'criterion': 'entropy', 'max_depth': 32, 'min_samples_split': 10, 'min_samples_leaf': 20}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:13,839] Trial 14 finished with value: 0.5284384694932782 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 9, 'min_samples_leaf': 18}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:15,858] Trial 15 finished with value: 0.5263702171664943 and parameters: {'n_estimators': 90, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:16,800] Trial 16 finished with value: 0.5253360910031024 and parameters: {'n_estimators': 52, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 20, 'min_samples_leaf': 17}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:18,767] Trial 17 finished with value: 0.5263702171664943 and parameters: {'n_estimators': 121, 'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 20}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:22,942] Trial 18 finished with value: 0.5305067218200621 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'max_depth': 29, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:25,469] Trial 19 finished with value: 0.5377456049638056 and parameters: {'n_estimators': 120, 'criterion': 'entropy', 'max_depth': 32, 'min_samples_split': 11, 'min_samples_leaf': 17}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:27,346] Trial 20 finished with value: 0.5439503619441571 and parameters: {'n_estimators': 85, 'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 7, 'min_samples_leaf': 18}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:29,203] Trial 21 finished with value: 0.5408479834539814 and parameters: {'n_estimators': 88, 'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 20}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:31,092] Trial 22 finished with value: 0.532574974146846 and parameters: {'n_estimators': 90, 'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 7, 'min_samples_leaf': 18}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:32,513] Trial 23 finished with value: 0.5356773526370218 and parameters: {'n_estimators': 57, 'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 8, 'min_samples_leaf': 16}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:34,113] Trial 24 finished with value: 0.5346432264736298 and parameters: {'n_estimators': 87, 'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 18}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:36,166] Trial 25 finished with value: 0.5274043433298863 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 15}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:37,748] Trial 26 finished with value: 0.531540847983454 and parameters: {'n_estimators': 81, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 20}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:39,010] Trial 27 finished with value: 0.516028955532575 and parameters: {'n_estimators': 61, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 18}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:41,400] Trial 28 finished with value: 0.5253360910031024 and parameters: {'n_estimators': 96, 'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 14}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:43,130] Trial 29 finished with value: 0.5232678386763185 and parameters: {'n_estimators': 67, 'criterion': 'entropy', 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:46,441] Trial 30 finished with value: 0.5274043433298863 and parameters: {'n_estimators': 133, 'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:48,589] Trial 31 finished with value: 0.5284384694932782 and parameters: {'n_estimators': 107, 'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 13, 'min_samples_leaf': 20}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:50,884] Trial 32 finished with value: 0.531540847983454 and parameters: {'n_estimators': 114, 'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 19}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:52,923] Trial 33 finished with value: 0.5367114788004137 and parameters: {'n_estimators': 78, 'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 16}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:55,411] Trial 34 finished with value: 0.5429162357807652 and parameters: {'n_estimators': 127, 'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 10, 'min_samples_leaf': 19}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:13:58,583] Trial 35 finished with value: 0.5377456049638056 and parameters: {'n_estimators': 127, 'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 7, 'min_samples_leaf': 17}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:01,240] Trial 36 finished with value: 0.5377456049638056 and parameters: {'n_estimators': 148, 'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 10, 'min_samples_leaf': 19}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:03,286] Trial 37 finished with value: 0.5305067218200621 and parameters: {'n_estimators': 74, 'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:05,973] Trial 38 finished with value: 0.5284384694932782 and parameters: {'n_estimators': 144, 'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 16}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:07,300] Trial 39 finished with value: 0.5118924508790073 and parameters: {'n_estimators': 84, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 13}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:09,505] Trial 40 finished with value: 0.5398138572905895 and parameters: {'n_estimators': 128, 'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 19}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:11,798] Trial 41 finished with value: 0.5398138572905895 and parameters: {'n_estimators': 128, 'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 19}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:13,331] Trial 42 finished with value: 0.531540847983454 and parameters: {'n_estimators': 96, 'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 19}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:16,095] Trial 43 finished with value: 0.5367114788004137 and parameters: {'n_estimators': 139, 'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 17}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:20,083] Trial 44 finished with value: 0.5408479834539814 and parameters: {'n_estimators': 159, 'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 18}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:27,369] Trial 45 finished with value: 0.5243019648397105 and parameters: {'n_estimators': 161, 'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 12, 'min_samples_leaf': 15}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:36,286] Trial 46 finished with value: 0.5336091003102379 and parameters: {'n_estimators': 191, 'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 11, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:39,150] Trial 47 finished with value: 0.4808686659772492 and parameters: {'n_estimators': 172, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 18}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:40,539] Trial 48 finished with value: 0.44570837642192346 and parameters: {'n_estimators': 199, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 20}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:43,741] Trial 49 finished with value: 0.5243019648397105 and parameters: {'n_estimators': 158, 'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 14}. Best is trial 13 with value: 0.5511892450879007.\n",
      "[I 2024-04-04 21:14:43,743] A new study created in memory with name: no-name-a2262570-8003-4b3d-83cc-91a1796d797c\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:14:46,329] Trial 0 finished with value: 0.4332988624612203 and parameters: {'n_estimators': 189, 'learning_rate': 0.001471491892844002, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 15}. Best is trial 0 with value: 0.4332988624612203.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:14:47,664] Trial 1 finished with value: 0.5211995863495347 and parameters: {'n_estimators': 72, 'learning_rate': 0.09581231492220263, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 16}. Best is trial 1 with value: 0.5211995863495347.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:14:48,755] Trial 2 finished with value: 0.43950361944157185 and parameters: {'n_estimators': 142, 'learning_rate': 0.0074338573584040125, 'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 12}. Best is trial 1 with value: 0.5211995863495347.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:14:54,528] Trial 3 finished with value: 0.5211995863495347 and parameters: {'n_estimators': 102, 'learning_rate': 0.06631640169468855, 'max_depth': 29, 'min_samples_split': 18, 'min_samples_leaf': 16}. Best is trial 1 with value: 0.5211995863495347.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:14:57,397] Trial 4 finished with value: 0.44881075491209926 and parameters: {'n_estimators': 180, 'learning_rate': 0.005241680375393741, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.5211995863495347.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:14:58,112] Trial 5 finished with value: 0.49431230610134436 and parameters: {'n_estimators': 126, 'learning_rate': 0.05808399045853087, 'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.5211995863495347.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:15:03,997] Trial 6 finished with value: 0.5367114788004137 and parameters: {'n_estimators': 118, 'learning_rate': 0.09313373798389285, 'max_depth': 21, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.5367114788004137.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:15:05,102] Trial 7 finished with value: 0.46328852119958636 and parameters: {'n_estimators': 59, 'learning_rate': 0.01793455581871474, 'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.5367114788004137.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:15:06,302] Trial 8 finished with value: 0.4364012409513961 and parameters: {'n_estimators': 97, 'learning_rate': 0.0010759599151514807, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 17}. Best is trial 6 with value: 0.5367114788004137.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:15:08,255] Trial 9 finished with value: 0.5046535677352637 and parameters: {'n_estimators': 101, 'learning_rate': 0.01754705201734874, 'max_depth': 9, 'min_samples_split': 17, 'min_samples_leaf': 13}. Best is trial 6 with value: 0.5367114788004137.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:15:17,156] Trial 10 finished with value: 0.5243019648397105 and parameters: {'n_estimators': 159, 'learning_rate': 0.034608151668541025, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.5367114788004137.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:15:25,330] Trial 11 finished with value: 0.5211995863495347 and parameters: {'n_estimators': 156, 'learning_rate': 0.038815829987152224, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.5367114788004137.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:15:32,235] Trial 12 finished with value: 0.5449844881075491 and parameters: {'n_estimators': 160, 'learning_rate': 0.036043973522456065, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.5449844881075491.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:15:38,777] Trial 13 finished with value: 0.532574974146846 and parameters: {'n_estimators': 128, 'learning_rate': 0.094150361909248, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 12 with value: 0.5449844881075491.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:15:52,046] Trial 14 finished with value: 0.5470527404343329 and parameters: {'n_estimators': 164, 'learning_rate': 0.033833230842912426, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.5470527404343329.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:16:04,801] Trial 15 finished with value: 0.5398138572905895 and parameters: {'n_estimators': 200, 'learning_rate': 0.024684989757398267, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.5470527404343329.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:16:21,870] Trial 16 finished with value: 0.5294725956566702 and parameters: {'n_estimators': 168, 'learning_rate': 0.013251159518987025, 'max_depth': 28, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.5470527404343329.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:16:34,706] Trial 17 finished with value: 0.5470527404343329 and parameters: {'n_estimators': 150, 'learning_rate': 0.03335943791214354, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.5470527404343329.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:16:47,697] Trial 18 finished with value: 0.5336091003102379 and parameters: {'n_estimators': 141, 'learning_rate': 0.009955472909109671, 'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.5470527404343329.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:16:56,246] Trial 19 finished with value: 0.5243019648397105 and parameters: {'n_estimators': 178, 'learning_rate': 0.02806204082209533, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 20}. Best is trial 14 with value: 0.5470527404343329.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:17:08,781] Trial 20 finished with value: 0.5346432264736298 and parameters: {'n_estimators': 143, 'learning_rate': 0.0526331365104347, 'max_depth': 32, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.5470527404343329.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:17:15,579] Trial 21 finished with value: 0.5491209927611168 and parameters: {'n_estimators': 161, 'learning_rate': 0.040893027047866015, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:17:22,538] Trial 22 finished with value: 0.5408479834539814 and parameters: {'n_estimators': 172, 'learning_rate': 0.044825722214973066, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:17:30,135] Trial 23 finished with value: 0.5305067218200621 and parameters: {'n_estimators': 155, 'learning_rate': 0.019896594633227075, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 11}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:17:37,125] Trial 24 finished with value: 0.5418821096173733 and parameters: {'n_estimators': 191, 'learning_rate': 0.026925319309593056, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:17:41,171] Trial 25 finished with value: 0.5201654601861427 and parameters: {'n_estimators': 145, 'learning_rate': 0.05423488273463916, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:17:45,497] Trial 26 finished with value: 0.5387797311271976 and parameters: {'n_estimators': 113, 'learning_rate': 0.036409573411303735, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:17:49,505] Trial 27 finished with value: 0.5346432264736298 and parameters: {'n_estimators': 132, 'learning_rate': 0.02530955850573119, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:17:57,295] Trial 28 finished with value: 0.5274043433298863 and parameters: {'n_estimators': 170, 'learning_rate': 0.07129276019029995, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:18:07,174] Trial 29 finished with value: 0.5398138572905895 and parameters: {'n_estimators': 192, 'learning_rate': 0.04169584714577785, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:18:12,413] Trial 30 finished with value: 0.5480868665977249 and parameters: {'n_estimators': 151, 'learning_rate': 0.012995036577463247, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:18:18,432] Trial 31 finished with value: 0.5398138572905895 and parameters: {'n_estimators': 151, 'learning_rate': 0.014276379008723474, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:18:24,740] Trial 32 finished with value: 0.5087900723888314 and parameters: {'n_estimators': 164, 'learning_rate': 0.004260831354281136, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:18:30,981] Trial 33 finished with value: 0.5408479834539814 and parameters: {'n_estimators': 181, 'learning_rate': 0.021968735719119444, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:18:37,295] Trial 34 finished with value: 0.5294725956566702 and parameters: {'n_estimators': 135, 'learning_rate': 0.01259896853659585, 'max_depth': 23, 'min_samples_split': 11, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:18:43,207] Trial 35 finished with value: 0.532574974146846 and parameters: {'n_estimators': 151, 'learning_rate': 0.03039780046725676, 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:18:47,220] Trial 36 finished with value: 0.5243019648397105 and parameters: {'n_estimators': 178, 'learning_rate': 0.046924942498875966, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 13}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:18:53,514] Trial 37 finished with value: 0.5418821096173733 and parameters: {'n_estimators': 138, 'learning_rate': 0.06733682962421177, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:18:57,536] Trial 38 finished with value: 0.5253360910031024 and parameters: {'n_estimators': 120, 'learning_rate': 0.020839925066571268, 'max_depth': 14, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:05,610] Trial 39 finished with value: 0.5408479834539814 and parameters: {'n_estimators': 150, 'learning_rate': 0.03159718679746382, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:12,114] Trial 40 finished with value: 0.5418821096173733 and parameters: {'n_estimators': 165, 'learning_rate': 0.07077158736269804, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:19,489] Trial 41 finished with value: 0.5439503619441571 and parameters: {'n_estimators': 159, 'learning_rate': 0.03307753323718989, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:27,839] Trial 42 finished with value: 0.5367114788004137 and parameters: {'n_estimators': 184, 'learning_rate': 0.04669198336216897, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:32,086] Trial 43 finished with value: 0.5470527404343329 and parameters: {'n_estimators': 87, 'learning_rate': 0.03853359361829026, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:36,548] Trial 44 finished with value: 0.5222337125129266 and parameters: {'n_estimators': 81, 'learning_rate': 0.01688734087587265, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:41,170] Trial 45 finished with value: 0.5191313340227508 and parameters: {'n_estimators': 86, 'learning_rate': 0.059748563842275, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:43,904] Trial 46 finished with value: 0.531540847983454 and parameters: {'n_estimators': 56, 'learning_rate': 0.024620387771889463, 'max_depth': 26, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:46,118] Trial 47 finished with value: 0.5243019648397105 and parameters: {'n_estimators': 67, 'learning_rate': 0.037989202010476085, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 9}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:52,123] Trial 48 finished with value: 0.5346432264736298 and parameters: {'n_estimators': 111, 'learning_rate': 0.0830050675981729, 'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.5491209927611168.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_18140\\3290382547.py:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
      "[I 2024-04-04 21:19:56,059] Trial 49 finished with value: 0.5429162357807652 and parameters: {'n_estimators': 89, 'learning_rate': 0.05353969045485134, 'max_depth': 21, 'min_samples_split': 16, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.5491209927611168.\n",
      "[I 2024-04-04 21:19:56,062] A new study created in memory with name: no-name-a090f950-96df-4825-a7b0-1b86a667f638\n",
      "[I 2024-04-04 21:19:59,864] Trial 0 finished with value: 0.6659772492244054 and parameters: {'C': 9.673323929851094, 'kernel': 'sigmoid', 'degree': 2}. Best is trial 0 with value: 0.6659772492244054.\n",
      "[I 2024-04-04 21:20:06,214] Trial 1 finished with value: 0.43536711478800416 and parameters: {'C': 5.8954276621148844, 'kernel': 'rbf', 'degree': 2}. Best is trial 0 with value: 0.6659772492244054.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Voting Classifier: 0.65\n",
      "ACCURACY for Voting Classifier: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "\n",
    "# Определение функций для оптимизации гиперпараметров случайного леса, градиентного бустинга и SVM\n",
    "def objective_rf(trial):\n",
    "    # Определение гиперпараметров для случайного леса\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def objective_gb(trial):\n",
    "    # Определение гиперпараметров для градиентного бустинга\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 32)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
    "\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def objective_svm(trial):\n",
    "    # Определение гиперпараметров для SVM\n",
    "    C = trial.suggest_float(\"C\", 0.01, 10.0)\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"])\n",
    "    degree = trial.suggest_int(\"degree\", 2, 5)\n",
    "\n",
    "    model = SVC(\n",
    "        C=C,\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        probability=True\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Оптимизация гиперпараметров для случайного леса\n",
    "study_rf = optuna.create_study(direction=\"maximize\")\n",
    "study_rf.optimize(objective_rf, n_trials=50)\n",
    "\n",
    "# Оптимизация гиперпараметров для градиентного бустинга\n",
    "study_gb = optuna.create_study(direction=\"maximize\")\n",
    "study_gb.optimize(objective_gb, n_trials=50)\n",
    "\n",
    "# Оптимизация гиперпараметров для SVM\n",
    "study_svm = optuna.create_study(direction=\"maximize\")\n",
    "study_svm.optimize(objective_svm, n_trials=2)\n",
    "\n",
    "# Получение лучших гиперпараметров для случайного леса, градиентного бустинга и SVM\n",
    "best_params_rf = study_rf.best_params\n",
    "best_params_gb = study_gb.best_params\n",
    "best_params_svm = study_svm.best_params\n",
    "\n",
    "# Создание моделей с лучшими гиперпараметрами\n",
    "best_model_rf = RandomForestClassifier(**best_params_rf)\n",
    "best_model_gb = GradientBoostingClassifier(**best_params_gb)\n",
    "best_model_svm = SVC(**best_params_svm, probability=True)  # probability=True для возможности использования soft voting\n",
    "\n",
    "# Обучение моделей\n",
    "best_model_rf.fit(X_train, y_train)\n",
    "best_model_gb.fit(X_train, y_train)\n",
    "best_model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Создание ансамбля с помощью голосования\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', best_model_rf), ('gb', best_model_gb), ('svm', best_model_svm)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Обучение ансамбля\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Оценка качества ансамбля\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "f1_voting = f1_score(y_test, y_pred_voting)\n",
    "\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "\n",
    "print(f\"F1 Score for Voting Classifier: {f1_voting:.2f}\")\n",
    "print(f\"ACCURACY for Voting Classifier: {accuracy_voting:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T21:12:41.788748Z",
     "end_time": "2024-04-04T21:20:29.176131Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 3011 features, but LogisticRegression is expecting 1 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[57], line 15\u001B[0m\n\u001B[0;32m     11\u001B[0m y2 \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mУспех предсказанного плана\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     13\u001B[0m best_model\u001B[38;5;241m.\u001B[39mfit(X, y)\n\u001B[1;32m---> 15\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mbest_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m#Лучшие гиперпараметры для логистической регрессии\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(best_params)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001B[0m, in \u001B[0;36mLinearClassifierMixin.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    438\u001B[0m \u001B[38;5;124;03mPredict class labels for samples in X.\u001B[39;00m\n\u001B[0;32m    439\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;124;03m    Vector containing the class labels for each sample.\u001B[39;00m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    450\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[1;32m--> 451\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(scores\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    453\u001B[0m     indices \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(scores \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mint\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:432\u001B[0m, in \u001B[0;36mLinearClassifierMixin.decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    429\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    430\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[1;32m--> 432\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    433\u001B[0m scores \u001B[38;5;241m=\u001B[39m safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_\u001B[38;5;241m.\u001B[39mT, dense_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_\n\u001B[0;32m    434\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39mreshape(scores, (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,)) \u001B[38;5;28;01mif\u001B[39;00m scores\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m scores\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:626\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    623\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 626\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:415\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[1;34m(self, X, reset)\u001B[0m\n\u001B[0;32m    412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[1;32m--> 415\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    416\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    417\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    418\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: X has 3011 features, but LogisticRegression is expecting 1 features as input."
     ]
    }
   ],
   "source": [
    "file_path = 'final_test_data.csv'\n",
    "data = pd.read_csv('final_test_data.csv')\n",
    "# Инициализация векторизатора\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Объединяем текстовые данные для векторизации\n",
    "combined_text = data['Задача en'] + \" \" + data['Обстановка en']\n",
    "X2 = tfidf_vectorizer.fit_transform(combined_text)\n",
    "\n",
    "# Целевая переменная\n",
    "y2 = data['Успех предсказанного плана']\n",
    "\n",
    "best_model.fit(X, y)\n",
    "\n",
    "y_pred = best_model.predict(X2)\n",
    "#Лучшие гиперпараметры для логистической регрессии\n",
    "print(best_params)\n",
    "\n",
    "# Оценим качество\n",
    "accuracy = accuracy_score(y2, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Вычисление F1-меры\n",
    "f1 = f1_score(y2, y_pred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Вычисление ROC-AUC\n",
    "roc_auc = roc_auc_score(y2, y_pred)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
