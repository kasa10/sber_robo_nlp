{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9f39658c2ea385d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:32.156796Z",
     "end_time": "2024-04-04T16:11:32.189149Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_path ='itmo_sber.csv'\n",
    "data = pd.read_csv('itmo_sber.csv')"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:32.465880Z",
     "end_time": "2024-04-04T16:11:32.813023Z"
    }
   },
   "id": "initial_id",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                    0\n",
      "Задача                        0\n",
      "Обстановка                    0\n",
      "Оптимальный план              0\n",
      "Задача en                     0\n",
      "Обстановка en                 0\n",
      "Оптимальный план en           0\n",
      "Предсказанный план            0\n",
      "Успех предсказанного плана    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:32.790568Z",
     "end_time": "2024-04-04T16:11:32.838576Z"
    }
   },
   "id": "4f83d29547bd4a37",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                          Задача  \\\n",
      "0           0   Приготовить горячий шоколад.    \n",
      "1           1     Заказать доставку еды домой   \n",
      "2           2  Реставрация старого комода\\r\\n   \n",
      "3           3            Приготовить сырники.   \n",
      "4           4               Нарезать колбасу.   \n",
      "\n",
      "                                          Обстановка  \\\n",
      "0  кухня, молоко, какао, сахар, кастрюля, ложка, ...   \n",
      "1  мобильный телефон, ресторанное меню, интернет,...   \n",
      "2  Старый комод, повреждения, шпатель, шкурка, ма...   \n",
      "3  Кухня, столешница, творог, мука, яйцо, сахар, ...   \n",
      "4  Кухня, колбаса, нож, доска для резки, холодиль...   \n",
      "\n",
      "                                    Оптимальный план  \\\n",
      "0  Откройте дверь. Зайдите на кухню. Закрйоте две...   \n",
      "1  Найдите стол. Подойдите к столу. Найдите мобил...   \n",
      "2  Подойдите к комоду.Найдите шкурку.Возьмите шку...   \n",
      "3  Подойти к столешнице. Найти творог. Взять твор...   \n",
      "4  Подойти к холодильнику. Открыть холодильник. Н...   \n",
      "\n",
      "                                Задача en  \\\n",
      "0                  Prepare hot chocolate.   \n",
      "1        Order food delivery to your home   \n",
      "2  Restoration of an old chest of drawers   \n",
      "3                    Prepare cheesecakes.   \n",
      "4                        Cut the sausage.   \n",
      "\n",
      "                                       Обстановка en  \\\n",
      "0  kitchen, milk, cocoa, sugar, pan, spoon, cabin...   \n",
      "1  mobile phone, restaurant menu, internet, money...   \n",
      "2  Old chest of drawers, damage, spatula, sandpap...   \n",
      "3  Kitchen, countertop, cottage cheese, flour, eg...   \n",
      "4  Kitchen, sausage, knife, cutting board, refrig...   \n",
      "\n",
      "                                 Оптимальный план en  \\\n",
      "0  Open the door. Walk to the kitchen. Close the ...   \n",
      "1  Find a table. Come to the table. Find a mobile...   \n",
      "2  Walk to the chest of drawers. Find the sandpap...   \n",
      "3  Walk to the tabletop. Find cottage cheese. Gra...   \n",
      "4  Walk to the refrigerator. Open the refrigerato...   \n",
      "\n",
      "                                  Предсказанный план  \\\n",
      "0    Walk to the closet. Open the closet. Find a ...   \n",
      "1    Come to the table. Find your phone. Grab the...   \n",
      "2    Find the chest of drawers. Walk to the chest...   \n",
      "3    Walk to the tabletop. Find a bowl. Grab a bo...   \n",
      "4    Walk to the refrigerator. Open the refrigera...   \n",
      "\n",
      "   Успех предсказанного плана  \n",
      "0                           0  \n",
      "1                           1  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           1  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:32.806819Z",
     "end_time": "2024-04-04T16:11:32.918410Z"
    }
   },
   "id": "ab427f19809c9a35",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успех предсказанного плана\n",
      "1    3234\n",
      "0    1600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Успех предсказанного плана'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:32.823524Z",
     "end_time": "2024-04-04T16:11:32.924087Z"
    }
   },
   "id": "f3bc9d36608379a3",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  Успех предсказанного плана\n",
      "count  4834.000000                 4834.000000\n",
      "mean   2416.500000                    0.669011\n",
      "std    1395.599931                    0.470618\n",
      "min       0.000000                    0.000000\n",
      "25%    1208.250000                    0.000000\n",
      "50%    2416.500000                    1.000000\n",
      "75%    3624.750000                    1.000000\n",
      "max    4833.000000                    1.000000\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:33.018916Z",
     "end_time": "2024-04-04T16:11:33.056740Z"
    }
   },
   "id": "f0c314486e8efdf9",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:33.573450Z",
     "end_time": "2024-04-04T16:11:33.616760Z"
    }
   },
   "id": "1c923bcde62c36a7",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['Задача'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:33.940053Z",
     "end_time": "2024-04-04T16:11:34.014306Z"
    }
   },
   "id": "dc8ed34120b864ec",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4834, 5402)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:34.357367Z",
     "end_time": "2024-04-04T16:11:34.388311Z"
    }
   },
   "id": "80d812178b855cd1",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kiril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kiril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kiril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kiril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words and word.isalpha()]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['Задача'] = data['Задача'].apply(preprocess_text)\n",
    "data['Обстановка'] = data['Обстановка'].apply(preprocess_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:34.782584Z",
     "end_time": "2024-04-04T16:11:38.340274Z"
    }
   },
   "id": "f9b1cbe4d757cb40",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Инициализация векторизатора\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Объединяем текстовые данные для векторизации\n",
    "combined_text = data['Задача'] + \" \" + data['Обстановка']\n",
    "X = tfidf_vectorizer.fit_transform(combined_text)\n",
    "\n",
    "# Целевая переменная\n",
    "y = data['Успех предсказанного плана']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:38.340274Z",
     "end_time": "2024-04-04T16:11:38.640226Z"
    }
   },
   "id": "98137111a26ab3f5",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:38.640226Z",
     "end_time": "2024-04-04T16:11:38.656828Z"
    }
   },
   "id": "c1017c0c2faaf512",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.6783867631851086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of the model: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:38.658887Z",
     "end_time": "2024-04-04T16:11:38.840875Z"
    }
   },
   "id": "fe5e1566521b8abe",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((3867, 1000), (967, 1000))"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "# Объединение текстовых полей\n",
    "data['combined_text'] = data['Задача en'] + ' ' + data['Обстановка en'] + ' ' + data['Предсказанный план']\n",
    "\n",
    "# Функция для очистки и нормализации текста\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Приведение к нижнему регистру\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Удаление лишних пробелов\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Удаление специальных символов\n",
    "    return text\n",
    "\n",
    "# Применение функции очистки к каждой строке объединенного текстового поля\n",
    "data['cleaned_text'] = data['combined_text'].apply(clean_text)\n",
    "\n",
    "# Подготовка данных и целевой переменной\n",
    "X = data['cleaned_text']\n",
    "y = data['Успех предсказанного плана']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Векторизация текста с использованием TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Ограничение на количество признаков для упрощения модели\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf.shape, X_test_tfidf.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:41.240560Z",
     "end_time": "2024-04-04T16:11:42.106711Z"
    }
   },
   "id": "456a168a5a40cd28",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.6763185108583247"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Обучение модели логистической регрессии\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Предсказание на тестовой выборке\n",
    "y_pred = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "# Расчет точности модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-04T16:11:43.440121Z",
     "end_time": "2024-04-04T16:11:43.504547Z"
    }
   },
   "id": "8dccc411b65807b6",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-04 16:11:45,240] A new study created in memory with name: no-name-77366017-8d89-4b7d-bc2a-6cd8ae987f1a\n",
      "[I 2024-04-04 16:11:46,364] Trial 0 finished with value: 0.7218045112781954 and parameters: {'C': 7352.7693075660445, 'penalty': 'l2', 'max_iter': 924}. Best is trial 0 with value: 0.7218045112781954.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:46,806] Trial 1 finished with value: 0.7218045112781954 and parameters: {'C': 4650.51694376259, 'penalty': 'l2', 'max_iter': 449}. Best is trial 0 with value: 0.7218045112781954.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:47,023] Trial 2 finished with value: 0.7310861423220973 and parameters: {'C': 359.8714376518027, 'penalty': 'l2', 'max_iter': 218}. Best is trial 2 with value: 0.7310861423220973.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:47,206] Trial 3 finished with value: 0.7309417040358746 and parameters: {'C': 297.5591425908796, 'penalty': 'l2', 'max_iter': 170}. Best is trial 2 with value: 0.7310861423220973.\n",
      "[I 2024-04-04 16:11:47,707] Trial 4 finished with value: 0.7314884068810771 and parameters: {'C': 387.305405214941, 'penalty': 'l2', 'max_iter': 931}. Best is trial 4 with value: 0.7314884068810771.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:47,890] Trial 5 finished with value: 0.7245283018867925 and parameters: {'C': 9498.565946958612, 'penalty': 'l2', 'max_iter': 143}. Best is trial 4 with value: 0.7314884068810771.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:48,673] Trial 6 finished with value: 0.7174076865109269 and parameters: {'C': 9951.239341720793, 'penalty': 'none', 'max_iter': 664}. Best is trial 4 with value: 0.7314884068810771.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:49,140] Trial 7 finished with value: 0.7227648384673179 and parameters: {'C': 7967.62496663034, 'penalty': 'l2', 'max_iter': 412}. Best is trial 4 with value: 0.7314884068810771.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:49,639] Trial 8 finished with value: 0.7193378480060196 and parameters: {'C': 902.0270574832845, 'penalty': 'none', 'max_iter': 454}. Best is trial 4 with value: 0.7314884068810771.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:50,140] Trial 9 finished with value: 0.7193378480060196 and parameters: {'C': 7858.884162799124, 'penalty': 'none', 'max_iter': 494}. Best is trial 4 with value: 0.7314884068810771.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:51,319] Trial 10 finished with value: 0.7208427389014297 and parameters: {'C': 2547.4813496762767, 'penalty': 'none', 'max_iter': 997}. Best is trial 4 with value: 0.7314884068810771.\n",
      "[I 2024-04-04 16:11:51,621] Trial 11 finished with value: 0.7488986784140969 and parameters: {'C': 51.51593231250786, 'penalty': 'l2', 'max_iter': 701}. Best is trial 11 with value: 0.7488986784140969.\n",
      "[I 2024-04-04 16:11:52,417] Trial 12 finished with value: 0.7242674680691209 and parameters: {'C': 2274.4760881752277, 'penalty': 'l2', 'max_iter': 774}. Best is trial 11 with value: 0.7488986784140969.\n",
      "[I 2024-04-04 16:11:53,315] Trial 13 finished with value: 0.7242674680691209 and parameters: {'C': 1958.351066982603, 'penalty': 'l2', 'max_iter': 818}. Best is trial 11 with value: 0.7488986784140969.\n",
      "[I 2024-04-04 16:11:53,540] Trial 14 finished with value: 0.7498176513493799 and parameters: {'C': 29.839661408815232, 'penalty': 'l2', 'max_iter': 645}. Best is trial 14 with value: 0.7498176513493799.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:54,356] Trial 15 finished with value: 0.7227648384673179 and parameters: {'C': 3760.9622672151895, 'penalty': 'l2', 'max_iter': 622}. Best is trial 14 with value: 0.7498176513493799.\n",
      "[I 2024-04-04 16:11:55,140] Trial 16 finished with value: 0.7252252252252253 and parameters: {'C': 1559.2206094676349, 'penalty': 'l2', 'max_iter': 704}. Best is trial 14 with value: 0.7498176513493799.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:55,547] Trial 17 finished with value: 0.7237237237237236 and parameters: {'C': 3282.7246486464683, 'penalty': 'l2', 'max_iter': 335}. Best is trial 14 with value: 0.7498176513493799.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:56,191] Trial 18 finished with value: 0.7198795180722891 and parameters: {'C': 1510.285141926194, 'penalty': 'none', 'max_iter': 616}. Best is trial 14 with value: 0.7498176513493799.\n",
      "[I 2024-04-04 16:11:56,607] Trial 19 finished with value: 0.7415066469719351 and parameters: {'C': 87.34040315517723, 'penalty': 'l2', 'max_iter': 791}. Best is trial 14 with value: 0.7498176513493799.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:57,223] Trial 20 finished with value: 0.7252252252252253 and parameters: {'C': 1198.6912270233715, 'penalty': 'l2', 'max_iter': 562}. Best is trial 14 with value: 0.7498176513493799.\n",
      "[I 2024-04-04 16:11:57,656] Trial 21 finished with value: 0.7318894697535474 and parameters: {'C': 467.21648302011977, 'penalty': 'l2', 'max_iter': 776}. Best is trial 14 with value: 0.7498176513493799.\n",
      "[I 2024-04-04 16:11:58,058] Trial 22 finished with value: 0.7383246849518161 and parameters: {'C': 114.88826183649807, 'penalty': 'l2', 'max_iter': 852}. Best is trial 14 with value: 0.7498176513493799.\n",
      "[I 2024-04-04 16:11:58,806] Trial 23 finished with value: 0.7252252252252253 and parameters: {'C': 1219.5472069876073, 'penalty': 'l2', 'max_iter': 731}. Best is trial 14 with value: 0.7498176513493799.\n",
      "[I 2024-04-04 16:11:59,034] Trial 24 finished with value: 0.7490855888807607 and parameters: {'C': 33.66797000669795, 'penalty': 'l2', 'max_iter': 558}. Best is trial 14 with value: 0.7498176513493799.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:59,623] Trial 25 finished with value: 0.7231807951987997 and parameters: {'C': 2689.1103211912305, 'penalty': 'l2', 'max_iter': 546}. Best is trial 14 with value: 0.7498176513493799.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:11:59,973] Trial 26 finished with value: 0.7227648384673179 and parameters: {'C': 1043.136893144059, 'penalty': 'none', 'max_iter': 325}. Best is trial 14 with value: 0.7498176513493799.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:12:00,606] Trial 27 finished with value: 0.7242674680691209 and parameters: {'C': 1973.2103361699692, 'penalty': 'l2', 'max_iter': 609}. Best is trial 14 with value: 0.7498176513493799.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:12:01,140] Trial 28 finished with value: 0.7261815453863466 and parameters: {'C': 947.2237991318657, 'penalty': 'l2', 'max_iter': 540}. Best is trial 14 with value: 0.7498176513493799.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-04-04 16:12:01,906] Trial 29 finished with value: 0.7212622088655146 and parameters: {'C': 5786.525416441278, 'penalty': 'l2', 'max_iter': 676}. Best is trial 14 with value: 0.7498176513493799.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'prepare hot chocolate kitchen milk cocoa sugar pan spoon cabinet mug chair sink the mug is in the closet the sink is located next to the stove milk cocoa sugar and a spoon are on the table the pan is on the stove walk to the closet open the closet find a mug grab a mug close the closet come to the table find a spoon grab a spoon find milk grab milk pour milk into a mug find cocoa grab cocoa add cocoa to the mug find sugar grab sugar add sugar to the mug place the cocoa on the table place sugar on the table grab a spoon stir the contents of the mug with a spoon place the spoon on the table find a saucepan grab a saucepan pour the contents of the mug into the pan place the mug on the table walk to the stove place the pan on the stove switch on the stove heat the milk prepare hot chocolate switch off the stove'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[39], line 48\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m#модель с лучшими гиперпараметрами\u001B[39;00m\n\u001B[0;32m     42\u001B[0m best_model \u001B[38;5;241m=\u001B[39m LogisticRegression(\n\u001B[0;32m     43\u001B[0m     C\u001B[38;5;241m=\u001B[39mbest_C,\n\u001B[0;32m     44\u001B[0m     penalty\u001B[38;5;241m=\u001B[39mbest_penalty,\n\u001B[0;32m     45\u001B[0m     max_iter\u001B[38;5;241m=\u001B[39mbest_max_iter\n\u001B[0;32m     46\u001B[0m )\n\u001B[1;32m---> 48\u001B[0m \u001B[43mbest_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m best_model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m#Лучшие гиперпараметры для логистической регрессии\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1208\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1205\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1206\u001B[0m     _dtype \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39mfloat64, np\u001B[38;5;241m.\u001B[39mfloat32]\n\u001B[1;32m-> 1208\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1209\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1210\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1211\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1212\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1213\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1214\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mliblinear\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msag\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msaga\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1215\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1216\u001B[0m check_classification_targets(y)\n\u001B[0;32m   1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:622\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    620\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    621\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 622\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    623\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1141\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1142\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1143\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1144\u001B[0m     )\n\u001B[1;32m-> 1146\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1147\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1148\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1149\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1150\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1151\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1152\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1153\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1158\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1159\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1162\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1164\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    913\u001B[0m         array \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(array, dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    914\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 915\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[0;32m    917\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    918\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[0;32m    919\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[1;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[0;32m    378\u001B[0m     array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39marray(array, order\u001B[38;5;241m=\u001B[39morder, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 380\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:953\u001B[0m, in \u001B[0;36mSeries.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m    906\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    907\u001B[0m \u001B[38;5;124;03mReturn the values as a NumPy array.\u001B[39;00m\n\u001B[0;32m    908\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    950\u001B[0m \u001B[38;5;124;03m      dtype='datetime64[ns]')\u001B[39;00m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    952\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m--> 953\u001B[0m arr \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    954\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m using_copy_on_write() \u001B[38;5;129;01mand\u001B[39;00m astype_is_view(values\u001B[38;5;241m.\u001B[39mdtype, arr\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[0;32m    955\u001B[0m     arr \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mview()\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'prepare hot chocolate kitchen milk cocoa sugar pan spoon cabinet mug chair sink the mug is in the closet the sink is located next to the stove milk cocoa sugar and a spoon are on the table the pan is on the stove walk to the closet open the closet find a mug grab a mug close the closet come to the table find a spoon grab a spoon find milk grab milk pour milk into a mug find cocoa grab cocoa add cocoa to the mug find sugar grab sugar add sugar to the mug place the cocoa on the table place sugar on the table grab a spoon stir the contents of the mug with a spoon place the spoon on the table find a saucepan grab a saucepan pour the contents of the mug into the pan place the mug on the table walk to the stove place the pan on the stove switch on the stove heat the milk prepare hot chocolate switch off the stove'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Определите пространство поиска гиперпараметров\n",
    "    C = trial.suggest_float(\"C\", 0.0001, 10000)\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l2\", \"none\"])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100, 1000)\n",
    "\n",
    "    # Модель логистической регрессии\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        max_iter=max_iter\n",
    "    )\n",
    "\n",
    "    # Обучение\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Предсказание\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "#лучшие гиперпараметры\n",
    "best_params = study.best_params\n",
    "best_C = best_params[\"C\"]\n",
    "best_penalty = best_params[\"penalty\"]\n",
    "best_max_iter = best_params[\"max_iter\"]\n",
    "\n",
    "#модель с лучшими гиперпараметрами\n",
    "best_model = LogisticRegression(\n",
    "    C=best_C,\n",
    "    penalty=best_penalty,\n",
    "    max_iter=best_max_iter\n",
    ")\n",
    "\n",
    "best_model.fit(X, y)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "#Лучшие гиперпараметры для логистической регрессии\n",
    "print(best_params)\n",
    "\n",
    "# Оценим качество\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Вычисление F1-меры\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Вычисление ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70648ff90d0c0b8a",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
